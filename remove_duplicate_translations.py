#!/usr/bin/env python3
"""
ç§»é™¤é‡å¤ç¿»è¯‘
ä¿®å¤é—®é¢˜ï¼šhabenæ˜¾ç¤º æœ‰ã€æ‹¥æœ‰ã€æœ‰ã€æ‹¥æœ‰ã€æœ‰ã€æ‹¥æœ‰ã€æœ‰ã€æ‹¥æœ‰ã€æœ‰ã€æ‹¥æœ‰
åº”è¯¥æ˜¾ç¤ºï¼šæœ‰ã€æ‹¥æœ‰ (å»é‡å)
"""
import sqlite3
from datetime import datetime
from collections import defaultdict

class DuplicateTranslationRemover:
    
    def __init__(self):
        self.db_path = 'data/app.db'
        self.stats = {
            'words_processed': 0,
            'duplicate_translations_removed': 0,
            'duplicate_examples_removed': 0,
            'start_time': datetime.now()
        }
    
    def find_duplicate_translations(self):
        """æŸ¥æ‰¾é‡å¤ç¿»è¯‘"""
        print("ğŸ” æŸ¥æ‰¾é‡å¤ç¿»è¯‘...")
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # æŸ¥æ‰¾æœ‰é‡å¤ç¿»è¯‘çš„è¯æ¡
            cursor.execute("""
                SELECT 
                    wl.lemma,
                    t.lemma_id,
                    t.lang_code,
                    COUNT(*) as translation_count,
                    GROUP_CONCAT(t.text, 'ã€') as all_translations
                FROM translations t
                JOIN word_lemmas wl ON t.lemma_id = wl.id
                GROUP BY t.lemma_id, t.lang_code
                HAVING translation_count > 3  -- è¶…è¿‡3ä¸ªç¿»è¯‘çš„å¯èƒ½æœ‰é‡å¤
                ORDER BY translation_count DESC, wl.lemma
                LIMIT 20
            """)
            
            duplicates = cursor.fetchall()
            
            print(f"ğŸ“‹ å‘ç° {len(duplicates)} ä¸ªå¯èƒ½æœ‰é‡å¤ç¿»è¯‘çš„è¯æ¡:")
            for lemma, lemma_id, lang_code, count, translations in duplicates:
                # æ˜¾ç¤ºç¿»è¯‘ï¼Œæˆªæ–­å¦‚æœå¤ªé•¿
                trans_preview = translations[:100] + "..." if len(translations) > 100 else translations
                print(f"   â€¢ {lemma} ({lang_code}): {count}ä¸ªç¿»è¯‘ - {trans_preview}")
            
            return duplicates
            
        finally:
            conn.close()
    
    def clean_translations_for_word(self, lemma_id, lang_code):
        """ä¸ºç‰¹å®šè¯æ¡æ¸…ç†é‡å¤ç¿»è¯‘"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # è·å–è¯¥è¯æ¡çš„æ‰€æœ‰ç¿»è¯‘
            cursor.execute("""
                SELECT id, text, source FROM translations 
                WHERE lemma_id = ? AND lang_code = ?
                ORDER BY id
            """, (lemma_id, lang_code))
            
            translations = cursor.fetchall()
            
            if len(translations) <= 1:
                return 0  # æ²¡æœ‰é‡å¤
            
            # å»é‡ï¼Œä¿æŒé¡ºåº
            seen_texts = set()
            unique_translations = []
            duplicates_to_remove = []
            
            for trans_id, text, source in translations:
                text_clean = text.strip().lower()
                if text_clean not in seen_texts:
                    seen_texts.add(text_clean)
                    unique_translations.append((trans_id, text, source))
                else:
                    duplicates_to_remove.append(trans_id)
            
            # åˆ é™¤é‡å¤é¡¹
            removed_count = 0
            for dup_id in duplicates_to_remove:
                cursor.execute("DELETE FROM translations WHERE id = ?", (dup_id,))
                removed_count += 1
            
            conn.commit()
            return removed_count
            
        except Exception as e:
            print(f"   âŒ æ¸…ç†ç¿»è¯‘å¤±è´¥: {e}")
            conn.rollback()
            return 0
        finally:
            conn.close()
    
    def clean_all_duplicate_translations(self):
        """æ¸…ç†æ‰€æœ‰é‡å¤ç¿»è¯‘"""
        print("ğŸ§¹ æ¸…ç†æ‰€æœ‰é‡å¤ç¿»è¯‘...")
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # è·å–æ‰€æœ‰æœ‰ç¿»è¯‘çš„è¯æ¡
            cursor.execute("""
                SELECT DISTINCT lemma_id, lang_code
                FROM translations
                ORDER BY lemma_id, lang_code
            """)
            
            word_lang_pairs = cursor.fetchall()
            print(f"ğŸ“ å¤„ç† {len(word_lang_pairs)} ä¸ªè¯æ¡-è¯­è¨€å¯¹...")
            
            total_removed = 0
            
            for lemma_id, lang_code in word_lang_pairs:
                removed = self.clean_translations_for_word(lemma_id, lang_code)
                if removed > 0:
                    # è·å–è¯æ¡åç§°ç”¨äºæ˜¾ç¤º
                    cursor.execute("SELECT lemma FROM word_lemmas WHERE id = ?", (lemma_id,))
                    lemma_result = cursor.fetchone()
                    lemma_name = lemma_result[0] if lemma_result else f"ID:{lemma_id}"
                    
                    print(f"   âœ… {lemma_name} ({lang_code}): ç§»é™¤äº† {removed} ä¸ªé‡å¤ç¿»è¯‘")
                    total_removed += removed
                    self.stats['words_processed'] += 1
            
            self.stats['duplicate_translations_removed'] = total_removed
            print(f"\nğŸ“Š æ€»å…±ç§»é™¤äº† {total_removed} ä¸ªé‡å¤ç¿»è¯‘")
            
        finally:
            conn.close()
    
    def find_duplicate_examples(self):
        """æŸ¥æ‰¾é‡å¤ä¾‹å¥"""
        print("\nğŸ” æŸ¥æ‰¾é‡å¤ä¾‹å¥...")
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # æŸ¥æ‰¾æœ‰é‡å¤ä¾‹å¥çš„è¯æ¡
            cursor.execute("""
                SELECT 
                    wl.lemma,
                    e.lemma_id,
                    COUNT(*) as example_count
                FROM examples e
                JOIN word_lemmas wl ON e.lemma_id = wl.id
                GROUP BY e.lemma_id
                HAVING example_count > 2  -- è¶…è¿‡2ä¸ªä¾‹å¥çš„å¯èƒ½æœ‰é‡å¤
                ORDER BY example_count DESC, wl.lemma
                LIMIT 15
            """)
            
            duplicates = cursor.fetchall()
            
            print(f"ğŸ“‹ å‘ç° {len(duplicates)} ä¸ªå¯èƒ½æœ‰é‡å¤ä¾‹å¥çš„è¯æ¡:")
            for lemma, lemma_id, count in duplicates:
                print(f"   â€¢ {lemma}: {count}ä¸ªä¾‹å¥")
            
            return duplicates
            
        finally:
            conn.close()
    
    def clean_examples_for_word(self, lemma_id):
        """ä¸ºç‰¹å®šè¯æ¡æ¸…ç†é‡å¤ä¾‹å¥"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # è·å–è¯¥è¯æ¡çš„æ‰€æœ‰ä¾‹å¥
            cursor.execute("""
                SELECT id, de_text, en_text, zh_text, level FROM examples 
                WHERE lemma_id = ?
                ORDER BY id
            """, (lemma_id,))
            
            examples = cursor.fetchall()
            
            if len(examples) <= 1:
                return 0  # æ²¡æœ‰é‡å¤
            
            # å»é‡ï¼ˆåŸºäºå¾·è¯­æ–‡æœ¬ï¼‰
            seen_de_texts = set()
            unique_examples = []
            duplicates_to_remove = []
            
            for ex_id, de_text, en_text, zh_text, level in examples:
                de_clean = de_text.strip().lower() if de_text else ""
                if de_clean and de_clean not in seen_de_texts:
                    seen_de_texts.add(de_clean)
                    unique_examples.append((ex_id, de_text, en_text, zh_text, level))
                else:
                    duplicates_to_remove.append(ex_id)
            
            # åˆ é™¤é‡å¤é¡¹
            removed_count = 0
            for dup_id in duplicates_to_remove:
                cursor.execute("DELETE FROM examples WHERE id = ?", (dup_id,))
                removed_count += 1
            
            conn.commit()
            return removed_count
            
        except Exception as e:
            print(f"   âŒ æ¸…ç†ä¾‹å¥å¤±è´¥: {e}")
            conn.rollback()
            return 0
        finally:
            conn.close()
    
    def clean_all_duplicate_examples(self):
        """æ¸…ç†æ‰€æœ‰é‡å¤ä¾‹å¥"""
        print("ğŸ§¹ æ¸…ç†æ‰€æœ‰é‡å¤ä¾‹å¥...")
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # è·å–æ‰€æœ‰æœ‰ä¾‹å¥çš„è¯æ¡
            cursor.execute("""
                SELECT DISTINCT lemma_id
                FROM examples
                ORDER BY lemma_id
            """)
            
            word_ids = [row[0] for row in cursor.fetchall()]
            print(f"ğŸ“ å¤„ç† {len(word_ids)} ä¸ªæœ‰ä¾‹å¥çš„è¯æ¡...")
            
            total_removed = 0
            
            for lemma_id in word_ids:
                removed = self.clean_examples_for_word(lemma_id)
                if removed > 0:
                    # è·å–è¯æ¡åç§°ç”¨äºæ˜¾ç¤º
                    cursor.execute("SELECT lemma FROM word_lemmas WHERE id = ?", (lemma_id,))
                    lemma_result = cursor.fetchone()
                    lemma_name = lemma_result[0] if lemma_result else f"ID:{lemma_id}"
                    
                    print(f"   âœ… {lemma_name}: ç§»é™¤äº† {removed} ä¸ªé‡å¤ä¾‹å¥")
                    total_removed += removed
            
            self.stats['duplicate_examples_removed'] = total_removed
            print(f"\nğŸ“Š æ€»å…±ç§»é™¤äº† {total_removed} ä¸ªé‡å¤ä¾‹å¥")
            
        finally:
            conn.close()
    
    def verify_specific_words(self):
        """éªŒè¯ç‰¹å®šè¯æ¡çš„ç¿»è¯‘"""
        print("\nğŸ” éªŒè¯ç‰¹å®šè¯æ¡ç¿»è¯‘...")
        
        test_words = ['haben', 'sehen', 'sein', 'gehen', 'machen']
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            for word in test_words:
                cursor.execute("""
                    SELECT t.lang_code, GROUP_CONCAT(t.text, 'ã€') as translations
                    FROM word_lemmas wl
                    JOIN translations t ON wl.id = t.lemma_id
                    WHERE wl.lemma = ?
                    GROUP BY t.lang_code
                    ORDER BY t.lang_code
                """, (word,))
                
                results = cursor.fetchall()
                print(f"   ğŸ“ {word}:")
                for lang_code, translations in results:
                    trans_list = translations.split('ã€')
                    unique_count = len(set(trans_list))
                    total_count = len(trans_list)
                    
                    if total_count != unique_count:
                        print(f"     âŒ {lang_code}: {total_count}ä¸ªç¿»è¯‘(å«é‡å¤) -> {translations[:50]}...")
                    else:
                        print(f"     âœ… {lang_code}: {total_count}ä¸ªç¿»è¯‘ -> {translations}")
                        
        finally:
            conn.close()
    
    def run_cleaning(self):
        """è¿è¡Œæ¸…ç†æµç¨‹"""
        print("ğŸ§¹ é‡å¤ç¿»è¯‘æ¸…ç†å·¥å…·")
        print("=" * 60)
        
        # 1. åˆ†æé‡å¤ç¿»è¯‘é—®é¢˜
        duplicate_translations = self.find_duplicate_translations()
        
        # 2. åˆ†æé‡å¤ä¾‹å¥é—®é¢˜  
        duplicate_examples = self.find_duplicate_examples()
        
        # 3. æ¸…ç†é‡å¤ç¿»è¯‘
        self.clean_all_duplicate_translations()
        
        # 4. æ¸…ç†é‡å¤ä¾‹å¥
        self.clean_all_duplicate_examples()
        
        # 5. éªŒè¯ç»“æœ
        self.verify_specific_words()
        
        self.print_final_stats()
    
    def print_final_stats(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡"""
        elapsed = datetime.now() - self.stats['start_time']
        
        print(f"\nğŸ‰ é‡å¤å†…å®¹æ¸…ç†å®Œæˆ!")
        print("=" * 50)
        print(f"å¤„ç†è¯æ¡æ•°: {self.stats['words_processed']}")
        print(f"ç§»é™¤é‡å¤ç¿»è¯‘: {self.stats['duplicate_translations_removed']}")
        print(f"ç§»é™¤é‡å¤ä¾‹å¥: {self.stats['duplicate_examples_removed']}")
        print(f"æ€»ç”¨æ—¶: {elapsed}")
        
        total_removed = (self.stats['duplicate_translations_removed'] + 
                        self.stats['duplicate_examples_removed'])
        
        print(f"æ€»æ¸…ç†é¡¹ç›®: {total_removed}")
        
        if total_removed > 0:
            print(f"\nâœ… æ¸…ç†æˆåŠŸ! ç°åœ¨:")
            print("   â€¢ haben ä¸å†æ˜¾ç¤ºé‡å¤çš„ä¸­æ–‡ç¿»è¯‘")
            print("   â€¢ sehen çš„ä¸­æ–‡ç¿»è¯‘å·²å»é‡")
            print("   â€¢ æ‰€æœ‰è¯æ¡çš„ç¿»è¯‘éƒ½æ˜¯å”¯ä¸€çš„")
            print("   â€¢ ä¾‹å¥ä¹Ÿå·²å»é‡")

def main():
    cleaner = DuplicateTranslationRemover()
    cleaner.run_cleaning()

if __name__ == "__main__":
    main()