#!/usr/bin/env python3
"""
å½»åº•æ¸…ç†é‡å¤ç¿»è¯‘ - æ›´æ¿€è¿›çš„å»é‡ç­–ç•¥
"""
import sqlite3
from datetime import datetime

class ThoroughDuplicateCleaner:
    
    def __init__(self):
        self.db_path = 'data/app.db'
        self.stats = {
            'words_cleaned': 0,
            'duplicates_removed': 0,
            'start_time': datetime.now()
        }
    
    def clean_word_translations(self, lemma_id, lang_code):
        """å½»åº•æ¸…ç†ä¸€ä¸ªè¯æ¡çš„ç¿»è¯‘é‡å¤"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # è·å–æ‰€æœ‰ç¿»è¯‘
            cursor.execute("""
                SELECT id, text, source FROM translations 
                WHERE lemma_id = ? AND lang_code = ?
                ORDER BY id
            """, (lemma_id, lang_code))
            
            translations = cursor.fetchall()
            
            if len(translations) <= 1:
                return 0
            
            # æ›´ä¸¥æ ¼çš„å»é‡ï¼šæŒ‰æ¸…ç†åçš„æ–‡æœ¬å†…å®¹å»é‡
            seen_clean_texts = set()
            keep_translations = []
            remove_ids = []
            
            for trans_id, text, source in translations:
                # æ¸…ç†æ–‡æœ¬ï¼šå»é™¤æ ‡ç‚¹ã€ç©ºæ ¼ã€è½¬å°å†™
                clean_text = text.strip().lower().replace('ï¼Œ', '').replace(',', '').replace('ã€‚', '').replace('.', '').replace(' ', '')
                
                if clean_text not in seen_clean_texts and clean_text:
                    seen_clean_texts.add(clean_text)
                    keep_translations.append((trans_id, text, source))
                else:
                    remove_ids.append(trans_id)
            
            # åˆ é™¤é‡å¤çš„ç¿»è¯‘
            removed_count = 0
            for remove_id in remove_ids:
                cursor.execute("DELETE FROM translations WHERE id = ?", (remove_id,))
                removed_count += 1
            
            conn.commit()
            return removed_count
            
        except Exception as e:
            print(f"   âŒ æ¸…ç†å¤±è´¥: {e}")
            conn.rollback()
            return 0
        finally:
            conn.close()
    
    def clean_all_translations(self):
        """æ¸…ç†æ‰€æœ‰ç¿»è¯‘é‡å¤"""
        print("ğŸ§¹ å½»åº•æ¸…ç†æ‰€æœ‰ç¿»è¯‘é‡å¤...")
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # æŸ¥æ‰¾æœ‰å¤šä¸ªç¿»è¯‘çš„è¯æ¡
            cursor.execute("""
                SELECT lemma_id, lang_code, COUNT(*) as count
                FROM translations
                GROUP BY lemma_id, lang_code
                HAVING count > 1
                ORDER BY count DESC
            """)
            
            duplicate_pairs = cursor.fetchall()
            print(f"ğŸ“‹ æ‰¾åˆ° {len(duplicate_pairs)} ä¸ªæœ‰é‡å¤ç¿»è¯‘çš„è¯æ¡-è¯­è¨€å¯¹")
            
            total_removed = 0
            
            for lemma_id, lang_code, count in duplicate_pairs:
                removed = self.clean_word_translations(lemma_id, lang_code)
                if removed > 0:
                    # è·å–è¯æ¡åç§°
                    cursor.execute("SELECT lemma FROM word_lemmas WHERE id = ?", (lemma_id,))
                    lemma_result = cursor.fetchone()
                    lemma_name = lemma_result[0] if lemma_result else f"ID:{lemma_id}"
                    
                    print(f"   âœ… {lemma_name} ({lang_code}): {count} -> {count-removed} (ç§»é™¤{removed}ä¸ª)")
                    total_removed += removed
                    self.stats['words_cleaned'] += 1
            
            self.stats['duplicates_removed'] = total_removed
            
        finally:
            conn.close()
    
    def fix_specific_words(self):
        """ä¿®å¤ç‰¹å®šçš„é—®é¢˜è¯æ¡"""
        print("\nğŸ¯ ä¿®å¤ç‰¹å®šé—®é¢˜è¯æ¡...")
        
        problem_words = {
            'haben': {
                'zh': ['æœ‰', 'æ‹¥æœ‰'],  # åªä¿ç•™è¿™ä¸¤ä¸ª
                'en': ['to have', 'have']  # åªä¿ç•™è¿™ä¸¤ä¸ª
            },
            'sehen': {
                'zh': ['çœ‹', 'è§', 'çœ‹è§'],  # ä¿ç•™è¿™ä¸‰ä¸ª
                'en': ['to see']  # åªä¿ç•™è¿™ä¸€ä¸ª
            }
        }
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            for lemma, lang_translations in problem_words.items():
                # è·å–è¯æ¡ID
                cursor.execute("SELECT id FROM word_lemmas WHERE lemma = ?", (lemma,))
                word_result = cursor.fetchone()
                
                if not word_result:
                    print(f"   âŒ æœªæ‰¾åˆ°è¯æ¡: {lemma}")
                    continue
                
                lemma_id = word_result[0]
                
                for lang_code, desired_translations in lang_translations.items():
                    # åˆ é™¤è¯¥è¯æ¡çš„æ‰€æœ‰ç¿»è¯‘
                    cursor.execute("DELETE FROM translations WHERE lemma_id = ? AND lang_code = ?", (lemma_id, lang_code))
                    
                    # é‡æ–°æ’å…¥æœŸæœ›çš„ç¿»è¯‘
                    for translation in desired_translations:
                        cursor.execute("""
                            INSERT INTO translations (lemma_id, lang_code, text, source)
                            VALUES (?, ?, ?, ?)
                        """, (lemma_id, lang_code, translation, 'manual_fix'))
                    
                    print(f"   âœ… {lemma} ({lang_code}): è®¾ç½®ä¸º {desired_translations}")
            
            conn.commit()
            
        except Exception as e:
            print(f"   âŒ ä¿®å¤ç‰¹å®šè¯æ¡å¤±è´¥: {e}")
            conn.rollback()
        finally:
            conn.close()
    
    def verify_results(self):
        """éªŒè¯æ¸…ç†ç»“æœ"""
        print("\nğŸ” éªŒè¯æ¸…ç†ç»“æœ...")
        
        test_words = ['haben', 'sehen', 'sein', 'gehen', 'machen']
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            for word in test_words:
                cursor.execute("""
                    SELECT t.lang_code, GROUP_CONCAT(t.text, 'ã€') as translations
                    FROM word_lemmas wl
                    JOIN translations t ON wl.id = t.lemma_id
                    WHERE wl.lemma = ?
                    GROUP BY t.lang_code
                    ORDER BY t.lang_code
                """, (word,))
                
                results = cursor.fetchall()
                print(f"   ğŸ“ {word}:")
                for lang_code, translations in results:
                    trans_list = translations.split('ã€')
                    unique_trans = list(dict.fromkeys(trans_list))  # ä¿æŒé¡ºåºå»é‡
                    
                    if len(trans_list) != len(unique_trans):
                        print(f"     âŒ {lang_code}: ä»æœ‰é‡å¤ -> {translations}")
                    else:
                        print(f"     âœ… {lang_code}: {translations}")
                        
        finally:
            conn.close()
    
    def run_thorough_cleaning(self):
        """è¿è¡Œå½»åº•æ¸…ç†"""
        print("ğŸ§¹ å½»åº•é‡å¤ç¿»è¯‘æ¸…ç†å·¥å…·")
        print("=" * 60)
        
        # 1. é€šç”¨æ¸…ç†
        self.clean_all_translations()
        
        # 2. ä¿®å¤ç‰¹å®šé—®é¢˜è¯æ¡
        self.fix_specific_words()
        
        # 3. éªŒè¯ç»“æœ
        self.verify_results()
        
        self.print_final_stats()
    
    def print_final_stats(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡"""
        elapsed = datetime.now() - self.stats['start_time']
        
        print(f"\nğŸ‰ å½»åº•æ¸…ç†å®Œæˆ!")
        print("=" * 50)
        print(f"æ¸…ç†è¯æ¡æ•°: {self.stats['words_cleaned']}")
        print(f"ç§»é™¤é‡å¤ç¿»è¯‘: {self.stats['duplicates_removed']}")
        print(f"æ€»ç”¨æ—¶: {elapsed}")
        
        print(f"\nâœ… ç°åœ¨:")
        print("   â€¢ haben ä¸å†æ˜¾ç¤ºé‡å¤çš„ æœ‰ã€æ‹¥æœ‰ã€æœ‰ã€æ‹¥æœ‰...")
        print("   â€¢ sehen ä¸å†æ˜¾ç¤ºé‡å¤çš„ çœ‹ã€çœ‹ã€è§ã€çœ‹è§ã€çœ‹ã€è§")
        print("   â€¢ æ‰€æœ‰ç¿»è¯‘éƒ½å·²å½»åº•å»é‡")

def main():
    cleaner = ThoroughDuplicateCleaner()
    cleaner.run_thorough_cleaning()

if __name__ == "__main__":
    main()