#!/usr/bin/env python3
"""
ç®€åŒ–è¯æ¡æ¸…ç†å·¥å…·
æ£€æµ‹æ˜æ˜¾çš„è‹±è¯­è¯æ¡å’Œé—®é¢˜è¯æ¡
"""
import sqlite3
import re
from datetime import datetime

class SimpleWordCleaner:
    
    def __init__(self):
        self.db_path = 'data/app.db'
        self.stats = {
            'words_analyzed': 0,
            'english_words_found': 0,
            'plural_words_found': 0,
            'suspicious_words_found': 0,
            'start_time': datetime.now()
        }
    
    def find_obvious_english_words(self):
        """æŸ¥æ‰¾æ˜æ˜¾çš„è‹±è¯­è¯æ¡"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        english_patterns = [
            'ing',    # English -ing verbs
            'tion',   # English -tion nouns  
            'ly',     # English -ly adverbs
            'ed',     # English -ed past tense
            'ness',   # English -ness nouns
            'ment',   # English -ment nouns
        ]
        
        obvious_english = [
            'the', 'and', 'or', 'but', 'with', 'for', 'to', 'of', 'in', 'on', 'at',
            'this', 'that', 'these', 'those', 'is', 'are', 'was', 'were',
            'have', 'has', 'had', 'will', 'would', 'could', 'should',
            'about', 'from', 'into', 'through', 'during', 'before', 'after',
            'above', 'below', 'between', 'among', 'within', 'without'
        ]
        
        try:
            # æŸ¥æ‰¾ä»¥è‹±è¯­åç¼€ç»“å°¾çš„è¯
            english_words = []
            for pattern in english_patterns:
                cursor.execute("""
                    SELECT id, lemma, pos, cefr, frequency 
                    FROM word_lemmas 
                    WHERE lemma LIKE ? AND LENGTH(lemma) > 3
                    ORDER BY lemma
                """, (f'%{pattern}',))
                
                results = cursor.fetchall()
                english_words.extend(results)
            
            # æŸ¥æ‰¾æ˜æ˜¾çš„è‹±è¯­è¯æ±‡
            placeholders = ','.join(['?' for _ in obvious_english])
            cursor.execute(f"""
                SELECT id, lemma, pos, cefr, frequency 
                FROM word_lemmas 
                WHERE lemma IN ({placeholders})
                ORDER BY lemma
            """, obvious_english)
            
            obvious_results = cursor.fetchall()
            english_words.extend(obvious_results)
            
            # å»é‡
            seen = set()
            unique_english = []
            for word in english_words:
                if word[0] not in seen:  # word[0] is id
                    seen.add(word[0])
                    unique_english.append(word)
            
            print(f"ğŸ“‹ å‘ç° {len(unique_english)} ä¸ªå¯èƒ½çš„è‹±è¯­è¯æ¡:")
            for word_id, lemma, pos, cefr, freq in unique_english[:20]:  # æ˜¾ç¤ºå‰20ä¸ª
                print(f"   â€¢ {lemma} ({pos}) - ID: {word_id}")
            
            if len(unique_english) > 20:
                print(f"   ... è¿˜æœ‰ {len(unique_english) - 20} ä¸ª")
            
            self.stats['english_words_found'] = len(unique_english)
            return unique_english
            
        finally:
            conn.close()
    
    def find_probable_plurals(self):
        """æŸ¥æ‰¾å¯èƒ½çš„å¤æ•°è¯æ¡ï¼ˆä½œä¸ºä¸»è¯æ¡ï¼‰"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # å¾·è¯­å¤æ•°å¸¸è§æ¨¡å¼
            cursor.execute("""
                SELECT id, lemma, pos, cefr, frequency, notes
                FROM word_lemmas 
                WHERE pos = 'noun'
                AND (
                    -- ä»¥-enç»“å°¾çš„å¤æ•°ï¼ˆå¾ˆå¤šå¾·è¯­åè¯å¤æ•°ï¼‰
                    (lemma LIKE '%en' AND LENGTH(lemma) > 4)
                    -- ä»¥-erç»“å°¾çš„å¤æ•°
                    OR (lemma LIKE '%er' AND LENGTH(lemma) > 4)
                    -- ä»¥-eç»“å°¾çš„å¤æ•°
                    OR (lemma LIKE '%e' AND LENGTH(lemma) > 3)
                    -- ä»¥-sç»“å°¾çš„å¤æ•°ï¼ˆå¤–æ¥è¯ï¼‰
                    OR lemma LIKE '%s'
                )
                AND (notes IS NULL OR notes NOT LIKE '%plural:%')  -- ä¸æ˜¯å·²çŸ¥çš„å¤æ•°ä¿¡æ¯
                ORDER BY lemma
                LIMIT 50
            """)
            
            probable_plurals = cursor.fetchall()
            
            print(f"ğŸ“‹ å‘ç° {len(probable_plurals)} ä¸ªå¯èƒ½çš„å¤æ•°ä¸»è¯æ¡:")
            for word_id, lemma, pos, cefr, freq, notes in probable_plurals:
                print(f"   â€¢ {lemma} - ID: {word_id}")
            
            self.stats['plural_words_found'] = len(probable_plurals)
            return probable_plurals
            
        finally:
            conn.close()
    
    def find_suspicious_words(self):
        """æŸ¥æ‰¾å¯ç–‘è¯æ¡"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # æŸ¥æ‰¾å¯ç–‘çš„è¯æ¡
            cursor.execute("""
                SELECT id, lemma, pos, cefr, frequency, notes
                FROM word_lemmas 
                WHERE 
                    -- éå¸¸çŸ­çš„è¯
                    (LENGTH(lemma) < 2)
                    -- æ²¡æœ‰ç­‰çº§å’Œé¢‘ç‡çš„è¯
                    OR (cefr IS NULL AND frequency IS NULL)
                    -- åŒ…å«æ•°å­—çš„è¯
                    OR lemma LIKE '%0%' OR lemma LIKE '%1%' OR lemma LIKE '%2%' 
                    OR lemma LIKE '%3%' OR lemma LIKE '%4%' OR lemma LIKE '%5%'
                    OR lemma LIKE '%6%' OR lemma LIKE '%7%' OR lemma LIKE '%8%' OR lemma LIKE '%9%'
                    -- åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„è¯
                    OR lemma LIKE '%@%' OR lemma LIKE '%#%' OR lemma LIKE '%$%'
                    OR lemma LIKE '%(%' OR lemma LIKE '%)%' OR lemma LIKE '%[%' OR lemma LIKE '%]%'
                ORDER BY LENGTH(lemma), lemma
                LIMIT 30
            """)
            
            suspicious_words = cursor.fetchall()
            
            print(f"ğŸ“‹ å‘ç° {len(suspicious_words)} ä¸ªå¯ç–‘è¯æ¡:")
            for word_id, lemma, pos, cefr, freq, notes in suspicious_words:
                print(f"   â€¢ '{lemma}' ({pos}) - ID: {word_id}")
            
            self.stats['suspicious_words_found'] = len(suspicious_words)
            return suspicious_words
            
        finally:
            conn.close()
    
    def check_word_relationships(self):
        """æ£€æŸ¥è¯æ¡å…³ç³»"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # æŸ¥æ‰¾å¯èƒ½çš„å•å¤æ•°å¯¹
            print(f"\nğŸ” æ£€æŸ¥å•å¤æ•°å…³ç³»:")
            
            cursor.execute("""
                SELECT w1.lemma as singular, w2.lemma as plural, w1.id as sing_id, w2.id as plur_id
                FROM word_lemmas w1
                JOIN word_lemmas w2 ON (
                    w2.lemma = w1.lemma || 'e'
                    OR w2.lemma = w1.lemma || 'en' 
                    OR w2.lemma = w1.lemma || 'er'
                    OR w2.lemma = w1.lemma || 's'
                )
                WHERE w1.pos = 'noun' AND w2.pos = 'noun'
                AND w1.id != w2.id
                ORDER BY w1.lemma
                LIMIT 20
            """)
            
            pairs = cursor.fetchall()
            for singular, plural, sing_id, plur_id in pairs:
                print(f"   â€¢ {singular} -> {plural} (IDs: {sing_id}, {plur_id})")
            
            return pairs
            
        finally:
            conn.close()
    
    def show_sample_words(self, category, count=10):
        """æ˜¾ç¤ºæ ·æœ¬è¯æ¡"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute("""
                SELECT lemma, pos, cefr, frequency, notes
                FROM word_lemmas 
                ORDER BY RANDOM()
                LIMIT ?
            """, (count,))
            
            words = cursor.fetchall()
            print(f"\nğŸ“ éšæœºæ ·æœ¬è¯æ¡ ({category}):")
            for lemma, pos, cefr, freq, notes in words:
                cefr_str = f"[{cefr}]" if cefr else "[?]"
                freq_str = f"(é¢‘ç‡:{freq})" if freq else ""
                notes_str = f" - {notes[:30]}..." if notes else ""
                print(f"   â€¢ {lemma} {cefr_str} ({pos}) {freq_str}{notes_str}")
            
        finally:
            conn.close()
    
    def run_analysis(self):
        """è¿è¡Œåˆ†æ"""
        print("ğŸ§¹ ç®€åŒ–è¯æ¡åˆ†æå·¥å…·")
        print("=" * 60)
        
        # 1. æŸ¥æ‰¾è‹±è¯­è¯æ¡
        print("1. æŸ¥æ‰¾è‹±è¯­è¯æ¡:")
        english_words = self.find_obvious_english_words()
        
        print(f"\n2. æŸ¥æ‰¾å¯èƒ½çš„å¤æ•°ä¸»è¯æ¡:")
        plural_words = self.find_probable_plurals()
        
        print(f"\n3. æŸ¥æ‰¾å¯ç–‘è¯æ¡:")
        suspicious_words = self.find_suspicious_words()
        
        print(f"\n4. æ£€æŸ¥è¯æ¡å…³ç³»:")
        pairs = self.check_word_relationships()
        
        # æ˜¾ç¤ºæ ·æœ¬
        self.show_sample_words("å½“å‰æ•°æ®åº“çŠ¶æ€", 15)
        
        self.print_final_stats()
        
        return {
            'english_words': english_words,
            'plural_words': plural_words, 
            'suspicious_words': suspicious_words,
            'pairs': pairs
        }
    
    def print_final_stats(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡"""
        elapsed = datetime.now() - self.stats['start_time']
        
        print(f"\nğŸ“Š åˆ†æå®Œæˆ!")
        print("=" * 50)
        print(f"å¯èƒ½çš„è‹±è¯­è¯æ¡: {self.stats['english_words_found']}")
        print(f"å¯èƒ½çš„å¤æ•°ä¸»è¯æ¡: {self.stats['plural_words_found']}")
        print(f"å¯ç–‘è¯æ¡: {self.stats['suspicious_words_found']}")
        print(f"åˆ†æç”¨æ—¶: {elapsed}")
        
        print(f"\nğŸ’¡ å»ºè®®:")
        print("1. æ£€æŸ¥ä¸Šè¿°è‹±è¯­è¯æ¡ï¼Œè€ƒè™‘åˆ é™¤")
        print("2. æ£€æŸ¥å¤æ•°ä¸»è¯æ¡ï¼Œè€ƒè™‘é‡å®šå‘åˆ°å•æ•°")
        print("3. æ£€æŸ¥å¯ç–‘è¯æ¡ï¼Œè€ƒè™‘åˆ é™¤æˆ–ä¿®æ­£")
        print("4. éªŒè¯å•å¤æ•°å…³ç³»æ˜¯å¦æ­£ç¡®")

def main():
    cleaner = SimpleWordCleaner()
    return cleaner.run_analysis()

if __name__ == "__main__":
    main()