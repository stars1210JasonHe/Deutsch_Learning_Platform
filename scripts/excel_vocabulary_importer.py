"""
Excelè¯æ±‡å¯¼å…¥å™¨ - æ”¯æŒè‡ªåŠ¨è¡¥å…¨ç¼ºå¤±çš„è¯­æ³•å½¢å¼
ä»Excelæ–‡ä»¶å¯¼å…¥è¯æ±‡åˆ°æ•°æ®åº“ï¼Œå¹¶ä½¿ç”¨OpenAIè‡ªåŠ¨è¡¥å…¨ç¼ºå¤±çš„åŠ¨è¯å˜ä½ç­‰
"""
import asyncio
import sys
import os
import re
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from app.db.session import SessionLocal
from app.models.word import WordLemma, Translation, Example, WordForm
from app.services.openai_service import OpenAIService
import zipfile
import xml.etree.ElementTree as ET


class ExcelVocabularyImporter:
    def __init__(self):
        self.db = SessionLocal()
        self.openai_service = OpenAIService()
        self.statistics = {
            'imported': 0,
            'skipped': 0,
            'enhanced': 0,
            'errors': 0
        }

    def parse_xlsx_file(self, file_path):
        """è§£æXLSXæ–‡ä»¶ï¼Œæå–è¯æ±‡æ•°æ®"""
        
        words_data = []
        
        try:
            with zipfile.ZipFile(file_path, 'r') as zip_ref:
                # è¯»å–å…±äº«å­—ç¬¦ä¸²
                shared_strings = []
                if 'xl/sharedStrings.xml' in zip_ref.namelist():
                    with zip_ref.open('xl/sharedStrings.xml') as f:
                        content = f.read().decode('utf-8')
                        root = ET.fromstring(content)
                        for si in root.findall('.//{http://schemas.openxmlformats.org/spreadsheetml/2006/main}t'):
                            shared_strings.append(si.text if si.text else "")
                
                # è¯»å–å·¥ä½œè¡¨æ•°æ®
                if 'xl/worksheets/sheet1.xml' in zip_ref.namelist():
                    with zip_ref.open('xl/worksheets/sheet1.xml') as f:
                        content = f.read().decode('utf-8')
                        root = ET.fromstring(content)
                        
                        # è§£ææ‰€æœ‰è¡Œ
                        rows = []
                        for row in root.findall('.//{http://schemas.openxmlformats.org/spreadsheetml/2006/main}row'):
                            row_data = []
                            for cell in row.findall('.//{http://schemas.openxmlformats.org/spreadsheetml/2006/main}c'):
                                value = ""
                                v_element = cell.find('.//{http://schemas.openxmlformats.org/spreadsheetml/2006/main}v')
                                if v_element is not None:
                                    # æ£€æŸ¥æ˜¯å¦æ˜¯å…±äº«å­—ç¬¦ä¸²å¼•ç”¨
                                    if cell.get('t') == 's':
                                        try:
                                            string_index = int(v_element.text)
                                            if string_index < len(shared_strings):
                                                value = shared_strings[string_index]
                                        except (ValueError, IndexError):
                                            value = v_element.text if v_element.text else ""
                                    else:
                                        value = v_element.text if v_element.text else ""
                                row_data.append(value)
                            rows.append(row_data)
                        
                        # å¤„ç†æ•°æ®ï¼ˆå‡è®¾ç¬¬ä¸€è¡Œæ˜¯æ ‡é¢˜ï¼‰
                        if len(rows) > 1:
                            headers = rows[0] if rows[0] else []
                            print(f"æ£€æµ‹åˆ°çš„åˆ—æ ‡é¢˜: {headers}")
                            
                            # æ˜ å°„å¸¸è§çš„åˆ—å
                            column_mapping = self._map_columns(headers)
                            print(f"åˆ—æ˜ å°„: {column_mapping}")
                            
                            for row_data in rows[1:]:
                                if len(row_data) > 0 and any(cell.strip() for cell in row_data if cell):
                                    word_info = self._extract_word_info(row_data, column_mapping)
                                    if word_info and word_info.get('german_word'):
                                        words_data.append(word_info)
                
        except Exception as e:
            print(f"âŒ è§£æExcelæ–‡ä»¶å¤±è´¥: {e}")
        
        return words_data

    def _map_columns(self, headers):
        """æ˜ å°„åˆ—æ ‡é¢˜åˆ°æ ‡å‡†å­—æ®µå"""
        
        column_mapping = {}
        
        for i, header in enumerate(headers):
            header_lower = header.lower().strip()
            
            # å¾·è¯­è¯æ±‡åˆ—
            if any(keyword in header_lower for keyword in ['german', 'deutsch', 'word', 'lemma', 'è¯æ±‡']):
                column_mapping['german_word'] = i
            
            # å† è¯åˆ—
            elif any(keyword in header_lower for keyword in ['article', 'der/die/das', 'å† è¯']):
                column_mapping['article'] = i
            
            # ç¿»è¯‘åˆ—
            elif any(keyword in header_lower for keyword in ['translation', 'english', 'meaning', 'ç¿»è¯‘', 'æ„æ€']):
                column_mapping['translation'] = i
            
            # ä¾‹å¥åˆ—
            elif any(keyword in header_lower for keyword in ['example', 'sentence', 'ä¾‹å¥']):
                column_mapping['example'] = i
            
            # è¯æ€§/åˆ†ç±»åˆ—
            elif any(keyword in header_lower for keyword in ['classification', 'pos', 'type', 'è¯æ€§', 'åˆ†ç±»']):
                column_mapping['classification'] = i
            
            # åªæœ‰åè¯åˆ—ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦ä¸ºåè¯ï¼‰
            elif any(keyword in header_lower for keyword in ['noun only', 'noun', 'åè¯']):
                column_mapping['noun_only'] = i
        
        return column_mapping

    def _extract_word_info(self, row_data, column_mapping):
        """ä»è¡Œæ•°æ®ä¸­æå–è¯æ±‡ä¿¡æ¯"""
        
        word_info = {}
        
        # è·å–åŸºæœ¬ä¿¡æ¯
        if 'german_word' in column_mapping:
            german_word = row_data[column_mapping['german_word']].strip()
            word_info['german_word'] = german_word
        
        if 'article' in column_mapping and column_mapping['article'] < len(row_data):
            article = row_data[column_mapping['article']].strip()
            word_info['article'] = article
        
        if 'translation' in column_mapping and column_mapping['translation'] < len(row_data):
            translation = row_data[column_mapping['translation']].strip()
            word_info['translation'] = translation
        
        if 'example' in column_mapping and column_mapping['example'] < len(row_data):
            example = row_data[column_mapping['example']].strip()
            word_info['example_de'] = example
        
        if 'classification' in column_mapping and column_mapping['classification'] < len(row_data):
            classification = row_data[column_mapping['classification']].strip()
            word_info['classification'] = classification
        
        # åˆ¤æ–­è¯æ€§
        word_info['pos'] = self._determine_pos(word_info)
        
        return word_info

    def _determine_pos(self, word_info):
        """æ ¹æ®å¯ç”¨ä¿¡æ¯åˆ¤æ–­è¯æ€§"""
        
        german_word = word_info.get('german_word', '')
        article = word_info.get('article', '')
        classification = word_info.get('classification', '')
        
        # å¦‚æœæœ‰å† è¯ï¼Œå¾ˆå¯èƒ½æ˜¯åè¯
        if article and article.lower() in ['der', 'die', 'das']:
            return 'noun'
        
        # æ ¹æ®åˆ†ç±»åˆ¤æ–­
        if classification:
            classification_lower = classification.lower()
            if any(keyword in classification_lower for keyword in ['noun', 'åè¯']):
                return 'noun'
            elif any(keyword in classification_lower for keyword in ['verb', 'åŠ¨è¯']):
                return 'verb'
            elif any(keyword in classification_lower for keyword in ['adj', 'adjective', 'å½¢å®¹è¯']):
                return 'adjective'
        
        # æ ¹æ®å¾·è¯­å•è¯ç‰¹å¾åˆ¤æ–­
        if german_word:
            # å¾·è¯­åè¯é€šå¸¸é¦–å­—æ¯å¤§å†™
            if german_word[0].isupper() and not german_word.startswith(('Der ', 'Die ', 'Das ')):
                return 'noun'
            
            # å¸¸è§åŠ¨è¯ç»“å°¾
            if german_word.endswith(('en', 'ern', 'eln')):
                return 'verb'
        
        return 'unknown'

    async def import_word_to_database(self, word_info, level):
        """å°†å•è¯å¯¼å…¥æ•°æ®åº“ï¼Œå¹¶è‡ªåŠ¨è¡¥å…¨ç¼ºå¤±çš„å½¢å¼"""
        
        german_word = word_info.get('german_word')
        if not german_word:
            return False
        
        try:
            # æ¸…ç†å¾·è¯­å•è¯ï¼ˆå»é™¤å¯èƒ½çš„å† è¯å‰ç¼€ï¼‰
            lemma = self._clean_german_word(german_word)
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing = self.db.query(WordLemma).filter(
                WordLemma.lemma.ilike(lemma)
            ).first()
            
            if existing:
                print(f"â© '{lemma}' å·²å­˜åœ¨ï¼Œè·³è¿‡")
                self.statistics['skipped'] += 1
                return False
            
            # åˆ›å»ºåŸºæœ¬è¯æ¡
            word = WordLemma(
                lemma=lemma,
                pos=word_info.get('pos', 'unknown'),
                cefr=level,
                notes=f"Imported from Excel ({level})"
            )
            
            self.db.add(word)
            self.db.commit()
            self.db.refresh(word)
            
            # æ·»åŠ å·²æœ‰çš„ç¿»è¯‘
            translation_text = word_info.get('translation')
            if translation_text:
                # å‡è®¾ç¿»è¯‘æ˜¯è‹±æ–‡ï¼Œåç»­å¯ä»¥æ”¹è¿›è¯­è¨€æ£€æµ‹
                translation = Translation(
                    lemma_id=word.id,
                    lang_code="en",
                    text=translation_text,
                    source="excel_import"
                )
                self.db.add(translation)
            
            # æ·»åŠ ä¾‹å¥
            example_de = word_info.get('example_de')
            if example_de:
                example = Example(
                    lemma_id=word.id,
                    de_text=example_de,
                    level=level
                )
                self.db.add(example)
            
            # å¤„ç†åè¯ç‰¹æ®Šä¿¡æ¯
            if word_info.get('pos') == 'noun' and word_info.get('article'):
                article_form = WordForm(
                    lemma_id=word.id,
                    form=f"{word_info['article']} {lemma}",
                    feature_key="article",
                    feature_value=word_info['article']
                )
                self.db.add(article_form)
            
            self.db.commit()
            
            # ä½¿ç”¨OpenAIè¡¥å…¨ç¼ºå¤±çš„ä¿¡æ¯
            enhanced = await self._enhance_word_with_openai(word, word_info)
            
            print(f"âœ… å¯¼å…¥: {lemma} ({word_info.get('pos', 'unknown')})" + 
                  (" [å¢å¼º]" if enhanced else ""))
            
            self.statistics['imported'] += 1
            if enhanced:
                self.statistics['enhanced'] += 1
            
            return True
            
        except Exception as e:
            print(f"âŒ å¯¼å…¥ '{german_word}' å¤±è´¥: {e}")
            self.statistics['errors'] += 1
            self.db.rollback()
            return False

    async def _enhance_word_with_openai(self, word: WordLemma, word_info: dict):
        """ä½¿ç”¨OpenAIè¡¥å…¨ç¼ºå¤±çš„è¯æ±‡ä¿¡æ¯"""
        
        try:
            # åªå¯¹åŠ¨è¯å’Œéœ€è¦è¡¥å……ä¿¡æ¯çš„è¯æ±‡è°ƒç”¨OpenAI
            needs_enhancement = (
                word.pos == 'verb' or  # åŠ¨è¯éœ€è¦å˜ä½è¡¨
                not word.translations or  # ç¼ºå°‘ç¿»è¯‘
                not word.examples  # ç¼ºå°‘ä¾‹å¥
            )
            
            if not needs_enhancement:
                return False
            
            print(f"ğŸ” ä½¿ç”¨OpenAIå¢å¼ºè¯æ±‡: {word.lemma}")
            analysis = await self.openai_service.analyze_word(word.lemma)
            
            enhanced = False
            
            # è¡¥å……ç¿»è¯‘
            if not word.translations:
                translations_en = analysis.get("translations_en", [])
                translations_zh = analysis.get("translations_zh", [])
                
                for trans in translations_en:
                    translation = Translation(
                        lemma_id=word.id,
                        lang_code="en",
                        text=trans,
                        source="openai_enhancement"
                    )
                    self.db.add(translation)
                    enhanced = True
                
                for trans in translations_zh:
                    translation = Translation(
                        lemma_id=word.id,
                        lang_code="zh",
                        text=trans,
                        source="openai_enhancement"
                    )
                    self.db.add(translation)
                    enhanced = True
            
            # è¡¥å……åŠ¨è¯å˜ä½è¡¨
            if word.pos == 'verb' and analysis.get("tables"):
                tables = analysis["tables"]
                for tense, forms in tables.items():
                    if isinstance(forms, dict):
                        for person, form in forms.items():
                            if form and person not in ["aux", "partizip_ii"]:
                                word_form = WordForm(
                                    lemma_id=word.id,
                                    form=form,
                                    feature_key="tense",
                                    feature_value=f"{tense}_{person}"
                                )
                                self.db.add(word_form)
                                enhanced = True
            
            # è¡¥å……ä¾‹å¥
            if not word.examples and analysis.get("example"):
                example_data = analysis["example"]
                example = Example(
                    lemma_id=word.id,
                    de_text=example_data.get("de", ""),
                    en_text=example_data.get("en", ""),
                    zh_text=example_data.get("zh", ""),
                    level=word.cefr or "A1"
                )
                self.db.add(example)
                enhanced = True
            
            if enhanced:
                self.db.commit()
            
            # é™åˆ¶APIè°ƒç”¨é¢‘ç‡
            await asyncio.sleep(1)
            
            return enhanced
            
        except Exception as e:
            print(f"âš ï¸ OpenAIå¢å¼ºå¤±è´¥: {e}")
            return False

    def _clean_german_word(self, word):
        """æ¸…ç†å¾·è¯­å•è¯ï¼Œç§»é™¤å† è¯å‰ç¼€ç­‰"""
        
        word = word.strip()
        
        # ç§»é™¤å† è¯
        for article in ['der ', 'die ', 'das ', 'Der ', 'Die ', 'Das ']:
            if word.startswith(article):
                return word[len(article):].strip()
        
        return word

    async def import_excel_file(self, file_path):
        """å¯¼å…¥å•ä¸ªExcelæ–‡ä»¶"""
        
        # ç¡®å®šçº§åˆ«
        level = "A1"
        if "A2" in file_path:
            level = "A2"
        elif "B1" in file_path:
            level = "B1"
        
        print(f"\nğŸ“š å¯¼å…¥Excelæ–‡ä»¶: {os.path.basename(file_path)} (çº§åˆ«: {level})")
        print("=" * 60)
        
        # è§£æExcelæ–‡ä»¶
        words_data = self.parse_xlsx_file(file_path)
        
        if not words_data:
            print("âŒ æœªæ‰¾åˆ°è¯æ±‡æ•°æ®")
            return
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(words_data)} ä¸ªè¯æ±‡æ¡ç›®")
        
        # å¯¼å…¥è¯æ±‡
        for i, word_info in enumerate(words_data):
            print(f"å¤„ç† {i+1}/{len(words_data)}: {word_info.get('german_word', 'N/A')}")
            await self.import_word_to_database(word_info, level)
            
            # æ¯å¤„ç†10ä¸ªè¯æ±‡ä¼‘æ¯ä¸€ä¸‹ï¼Œé¿å…APIé™åˆ¶
            if (i + 1) % 10 == 0:
                print(f"å·²å¤„ç† {i+1} ä¸ªè¯æ±‡ï¼Œä¼‘æ¯2ç§’...")
                await asyncio.sleep(2)
        
        print(f"\nâœ… {os.path.basename(file_path)} å¯¼å…¥å®Œæˆ")

    async def import_all_excel_files(self):
        """å¯¼å…¥æ‰€æœ‰Excelæ–‡ä»¶"""
        
        excel_files = [
            "/mnt/e/LanguageLearning/german_vocabulary_A1_sample.xlsx",
            "/mnt/e/LanguageLearning/german_vocabulary_A2_sample.xlsx", 
            "/mnt/e/LanguageLearning/german_vocabulary_B1_sample.xlsx"
        ]
        
        print("ğŸš€ å¼€å§‹æ‰¹é‡å¯¼å…¥Excelè¯æ±‡æ–‡ä»¶")
        print("=" * 60)
        
        for file_path in excel_files:
            if os.path.exists(file_path):
                await self.import_excel_file(file_path)
            else:
                print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        print(f"\nğŸ“Š å¯¼å…¥ç»Ÿè®¡:")
        print(f"   - æˆåŠŸå¯¼å…¥: {self.statistics['imported']}")
        print(f"   - è·³è¿‡å·²å­˜åœ¨: {self.statistics['skipped']}")
        print(f"   - OpenAIå¢å¼º: {self.statistics['enhanced']}")
        print(f"   - é”™è¯¯: {self.statistics['errors']}")
        
        self.db.close()

    def show_preview(self, file_path, limit=5):
        """é¢„è§ˆExcelæ–‡ä»¶å†…å®¹"""
        
        print(f"\nğŸ‘€ é¢„è§ˆæ–‡ä»¶: {os.path.basename(file_path)}")
        print("=" * 40)
        
        words_data = self.parse_xlsx_file(file_path)
        
        for i, word_info in enumerate(words_data[:limit]):
            print(f"\nè¯æ±‡ {i+1}:")
            for key, value in word_info.items():
                print(f"  {key}: {value}")


async def main():
    """ä¸»å‡½æ•°"""
    
    if len(sys.argv) < 2:
        print("Excelè¯æ±‡å¯¼å…¥å™¨ä½¿ç”¨æ–¹æ³•:")
        print("  python excel_vocabulary_importer.py preview      # é¢„è§ˆæ‰€æœ‰æ–‡ä»¶")
        print("  python excel_vocabulary_importer.py import       # å¯¼å…¥æ‰€æœ‰æ–‡ä»¶")
        print("  python excel_vocabulary_importer.py import A1    # åªå¯¼å…¥A1æ–‡ä»¶")
        return
    
    importer = ExcelVocabularyImporter()
    command = sys.argv[1]
    
    if command == "preview":
        excel_files = [
            "/mnt/e/LanguageLearning/german_vocabulary_A1_sample.xlsx",
            "/mnt/e/LanguageLearning/german_vocabulary_A2_sample.xlsx", 
            "/mnt/e/LanguageLearning/german_vocabulary_B1_sample.xlsx"
        ]
        
        for file_path in excel_files:
            if os.path.exists(file_path):
                importer.show_preview(file_path)
                
    elif command == "import":
        if len(sys.argv) > 2:
            level = sys.argv[2].upper()
            file_path = f"/mnt/e/LanguageLearning/german_vocabulary_{level}_sample.xlsx"
            if os.path.exists(file_path):
                await importer.import_excel_file(file_path)
            else:
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        else:
            await importer.import_all_excel_files()
    
    else:
        print("âŒ æ— æ•ˆçš„å‘½ä»¤")


if __name__ == "__main__":
    asyncio.run(main())