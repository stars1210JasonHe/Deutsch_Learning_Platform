#!/usr/bin/env python3
"""
ä¸ºç¼ºå°‘ä¾‹å¥çš„å¾·è¯­è¯æ±‡ç”Ÿæˆä¾‹å¥
ä½¿ç”¨OpenAI APIç”Ÿæˆé«˜è´¨é‡çš„ä¸‰è¯­ä¾‹å¥
"""
import sqlite3
import asyncio
import sys
import os
from datetime import datetime
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.getcwd())

try:
    from app.services.openai_service import OpenAIService
    from app.config import settings
except ImportError as e:
    print(f"âŒ æ— æ³•å¯¼å…¥åº”ç”¨æ¨¡å—: {e}")
    print("è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ")
    sys.exit(1)

class ExampleGenerator:
    """ä¾‹å¥ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.db_path = 'data/app.db'
        self.openai_service = OpenAIService()
        self.stats = {
            'words_processed': 0,
            'examples_generated': 0,
            'errors': 0,
            'start_time': datetime.now()
        }
        
    def get_words_without_examples(self, limit=50):
        """è·å–æ²¡æœ‰ä¾‹å¥çš„è¯æ±‡åˆ—è¡¨"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # ä¼˜å…ˆå¤„ç†å¸¸ç”¨è¯æ±‡å’Œç”¨æˆ·å…³å¿ƒçš„è¯æ±‡
            priority_words = [
                'bezahlen', 'kreuzen', 'arbeiten', 'leben', 'kaufen', 'verkaufen',
                'schlafen', 'fahren', 'laufen', 'machen', 'sagen', 'wissen',
                'kommen', 'geben', 'nehmen', 'denken', 'finden', 'spielen',
                'lernen', 'verstehen', 'sprechen', 'hÃ¶ren', 'lesen', 'schreiben'
            ]
            
            # å…ˆè·å–ä¼˜å…ˆè¯æ±‡ä¸­ç¼ºå°‘ä¾‹å¥çš„
            priority_placeholders = ','.join('?' * len(priority_words))
            cursor.execute(f"""
                SELECT wl.id, wl.lemma, wl.pos
                FROM word_lemmas wl
                LEFT JOIN examples e ON e.lemma_id = wl.id
                WHERE wl.lemma IN ({priority_placeholders})
                  AND e.id IS NULL
                ORDER BY wl.lemma
            """, priority_words)
            
            priority_results = cursor.fetchall()
            
            # å¦‚æœè¿˜éœ€è¦æ›´å¤šè¯æ±‡ï¼Œè·å–å…¶ä»–ç¼ºå°‘ä¾‹å¥çš„è¯æ±‡
            remaining_limit = limit - len(priority_results)
            if remaining_limit > 0:
                cursor.execute("""
                    SELECT wl.id, wl.lemma, wl.pos
                    FROM word_lemmas wl
                    LEFT JOIN examples e ON e.lemma_id = wl.id
                    WHERE e.id IS NULL
                      AND wl.lemma NOT IN ({})
                    ORDER BY wl.frequency DESC, wl.lemma
                    LIMIT ?
                """.format(priority_placeholders), priority_words + [remaining_limit])
                
                other_results = cursor.fetchall()
                results = priority_results + other_results
            else:
                results = priority_results[:limit]
            
            print(f"ğŸ“‹ æ‰¾åˆ° {len(results)} ä¸ªéœ€è¦ç”Ÿæˆä¾‹å¥çš„è¯æ±‡")
            print(f"   å…¶ä¸­ä¼˜å…ˆè¯æ±‡: {len(priority_results)} ä¸ª")
            
            return results
            
        finally:
            conn.close()
    
    async def generate_example_for_word(self, lemma_id, lemma, pos):
        """ä¸ºå•ä¸ªè¯æ±‡ç”Ÿæˆä¾‹å¥"""
        print(f"ğŸ¯ ç”Ÿæˆä¾‹å¥: {lemma} ({pos})")
        
        try:
            # æ„å»ºæç¤ºè¯
            prompt = f"""
ä¸ºå¾·è¯­å•è¯ "{lemma}" ({pos}) ç”Ÿæˆä¸€ä¸ªå®ç”¨çš„ä¾‹å¥ã€‚è¦æ±‚:

1. ä¾‹å¥åº”è¯¥æ˜¯æ—¥å¸¸ç”Ÿæ´»ä¸­å¸¸ç”¨çš„åœºæ™¯
2. è¯­æ³•æ­£ç¡®ï¼Œç”¨è¯é€‚å½“
3. æä¾›å¾·è¯­ã€è‹±è¯­ã€ä¸­æ–‡ä¸‰ä¸ªç‰ˆæœ¬
4. å¾·è¯­ä¾‹å¥é•¿åº¦é€‚ä¸­(5-15ä¸ªå•è¯)
5. å¦‚æœæ˜¯åŠ¨è¯ï¼Œä½¿ç”¨å¸¸è§çš„æ—¶æ€å’Œäººç§°
6. å¦‚æœæ˜¯åè¯ï¼Œä½¿ç”¨é€‚å½“çš„å† è¯

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›:
{{
    "de": "å¾·è¯­ä¾‹å¥",
    "en": "English example sentence", 
    "zh": "ä¸­æ–‡ä¾‹å¥"
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""
            
            # è°ƒç”¨OpenAI API
            response = await self.openai_service._make_request(
                messages=[{"role": "user", "content": prompt}],
                max_tokens=200,
                temperature=0.7
            )
            
            if not response or 'choices' not in response or not response['choices']:
                raise Exception("OpenAI APIè¿”å›ç©ºå“åº”")
                
            content = response['choices'][0]['message']['content'].strip()
            
            # è§£æJSONå“åº”
            try:
                example_data = json.loads(content)
                if not all(key in example_data for key in ['de', 'en', 'zh']):
                    raise ValueError("å“åº”ç¼ºå°‘å¿…è¦å­—æ®µ")
                    
                # éªŒè¯ä¾‹å¥è´¨é‡
                if not example_data['de'] or lemma.lower() not in example_data['de'].lower():
                    print(f"   âš ï¸  è­¦å‘Š: ç”Ÿæˆçš„ä¾‹å¥å¯èƒ½ä¸åŒ…å«ç›®æ ‡è¯æ±‡")
                
                return example_data
                
            except json.JSONDecodeError:
                raise Exception(f"æ— æ³•è§£æJSONå“åº”: {content}")
                
        except Exception as e:
            print(f"   âŒ ç”Ÿæˆå¤±è´¥: {e}")
            self.stats['errors'] += 1
            return None
    
    def save_example_to_database(self, lemma_id, example_data):
        """ä¿å­˜ä¾‹å¥åˆ°æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute("""
                INSERT INTO examples (lemma_id, de_text, en_text, zh_text)
                VALUES (?, ?, ?, ?)
            """, (
                lemma_id,
                example_data['de'],
                example_data['en'], 
                example_data['zh']
            ))
            
            conn.commit()
            self.stats['examples_generated'] += 1
            print(f"   âœ… ä¿å­˜æˆåŠŸ")
            print(f"      DE: {example_data['de']}")
            print(f"      EN: {example_data['en']}")
            print(f"      ZH: {example_data['zh']}")
            
        except Exception as e:
            print(f"   âŒ ä¿å­˜å¤±è´¥: {e}")
            conn.rollback()
            raise
            
        finally:
            conn.close()
    
    async def generate_examples_batch(self, batch_size=10, delay=1.0):
        """æ‰¹é‡ç”Ÿæˆä¾‹å¥"""
        print("ğŸš€ å¼€å§‹æ‰¹é‡ç”Ÿæˆä¾‹å¥")
        print("=" * 50)
        
        words_without_examples = self.get_words_without_examples(batch_size)
        
        if not words_without_examples:
            print("âœ… æ‰€æœ‰è¯æ±‡éƒ½å·²æœ‰ä¾‹å¥!")
            return
        
        print(f"ğŸ“ å°†å¤„ç† {len(words_without_examples)} ä¸ªè¯æ±‡:")
        for lemma_id, lemma, pos in words_without_examples[:5]:
            print(f"   â€¢ {lemma} ({pos})")
        if len(words_without_examples) > 5:
            print(f"   ... è¿˜æœ‰ {len(words_without_examples) - 5} ä¸ª")
        
        print()
        
        for i, (lemma_id, lemma, pos) in enumerate(words_without_examples, 1):
            print(f"[{i}/{len(words_without_examples)}] ", end="")
            self.stats['words_processed'] += 1
            
            try:
                # ç”Ÿæˆä¾‹å¥
                example_data = await self.generate_example_for_word(lemma_id, lemma, pos)
                
                if example_data:
                    # ä¿å­˜åˆ°æ•°æ®åº“
                    self.save_example_to_database(lemma_id, example_data)
                
                # å»¶è¿Ÿä»¥é¿å…APIé™åˆ¶
                if delay > 0 and i < len(words_without_examples):
                    await asyncio.sleep(delay)
                    
            except Exception as e:
                print(f"   âŒ å¤„ç† {lemma} æ—¶å‡ºé”™: {e}")
                self.stats['errors'] += 1
                continue
        
        self.print_final_stats()
    
    def print_final_stats(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡"""
        elapsed = datetime.now() - self.stats['start_time']
        
        print(f"\nğŸ‰ ä¾‹å¥ç”Ÿæˆå®Œæˆ!")
        print("=" * 50)
        print(f"å¤„ç†è¯æ±‡: {self.stats['words_processed']}")
        print(f"ç”Ÿæˆä¾‹å¥: {self.stats['examples_generated']}")
        print(f"é”™è¯¯æ•°é‡: {self.stats['errors']}")
        print(f"æˆåŠŸç‡: {(self.stats['examples_generated']/self.stats['words_processed']*100):.1f}%")
        print(f"æ€»ç”¨æ—¶: {elapsed}")
        
        # æ£€æŸ¥bezahlenæ˜¯å¦å·²æœ‰ä¾‹å¥
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        try:
            cursor.execute("""
                SELECT e.de_text FROM examples e
                JOIN word_lemmas wl ON wl.id = e.lemma_id  
                WHERE wl.lemma = 'bezahlen'
                LIMIT 1
            """)
            bezahlen_example = cursor.fetchone()
            
            if bezahlen_example:
                print(f"\nâœ… bezahlenç°åœ¨æœ‰ä¾‹å¥: {bezahlen_example[0]}")
            else:
                print(f"\nâš ï¸  bezahlenä»ç„¶æ²¡æœ‰ä¾‹å¥")
                
        finally:
            conn.close()

async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ä¸ºå¾·è¯­è¯æ±‡ç”Ÿæˆä¾‹å¥')
    parser.add_argument('--batch-size', type=int, default=20, help='æ‰¹æ¬¡å¤§å° (é»˜è®¤: 20)')
    parser.add_argument('--delay', type=float, default=1.0, help='APIè°ƒç”¨å»¶è¿Ÿ (ç§’, é»˜è®¤: 1.0)')
    parser.add_argument('--priority-only', action='store_true', help='åªå¤„ç†ä¼˜å…ˆè¯æ±‡')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥APIå¯†é’¥
    if not hasattr(settings, 'openai_api_key') or not settings.openai_api_key:
        print("âŒ é”™è¯¯: æœªé…ç½®OpenAI APIå¯†é’¥")
        print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY")
        return
    
    generator = ExampleGenerator()
    await generator.generate_examples_batch(
        batch_size=args.batch_size,
        delay=args.delay
    )

if __name__ == "__main__":
    asyncio.run(main())