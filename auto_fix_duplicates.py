#!/usr/bin/env python3
"""
è‡ªåŠ¨ä¿®å¤é‡å¤è¯æ¡ - æ— éœ€ç”¨æˆ·äº¤äº’
"""
import sqlite3
import re
from datetime import datetime
from collections import defaultdict

class AutoDuplicateFixer:
    
    def __init__(self):
        self.db_path = 'data/app.db'
        self.stats = {
            'lemmas_merged': 0,
            'forms_moved': 0,
            'duplicates_found': 0,
            'start_time': datetime.now()
        }
    
    def run_auto_fix(self):
        """è‡ªåŠ¨è¿è¡Œä¿®å¤æµç¨‹"""
        print("ğŸš€ è‡ªåŠ¨ä¿®å¤é‡å¤è¯æ¡")
        print("=" * 60)
        
        # åˆ†æé‡å¤è¯æ¡
        verb_groups, noun_groups = self.analyze_duplicates()
        
        # è‡ªåŠ¨åˆå¹¶
        self.merge_duplicate_lemmas(verb_groups, noun_groups)
        self.print_final_stats()
        
        return self.stats
    
    def analyze_duplicates(self):
        """åˆ†æé‡å¤çš„è¯æ¡"""
        print("ğŸ” åˆ†æé‡å¤è¯æ¡...")
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # æŸ¥æ‰¾åŠ¨è¯é‡å¤
        cursor.execute("""
            SELECT lemma, pos, id, cefr, frequency 
            FROM word_lemmas 
            WHERE pos = 'verb' 
            ORDER BY lemma
        """)
        verbs = cursor.fetchall()
        verb_groups = self.group_similar_verbs(verbs)
        
        # æŸ¥æ‰¾åè¯é‡å¤  
        cursor.execute("""
            SELECT lemma, pos, id, cefr, frequency 
            FROM word_lemmas 
            WHERE pos = 'noun' 
            ORDER BY lemma
        """)
        nouns = cursor.fetchall()
        noun_groups = self.group_singular_plural_nouns(nouns)
        
        verb_duplicates = sum(1 for v in verb_groups.values() if len(v) > 1)
        noun_duplicates = sum(1 for v in noun_groups.values() if len(v) > 1)
        
        print(f"ğŸ“Š å‘ç°é‡å¤ç»„: åŠ¨è¯ {verb_duplicates} ç»„, åè¯ {noun_duplicates} ç»„")
        
        conn.close()
        return verb_groups, noun_groups
    
    def group_similar_verbs(self, verbs):
        """å°†ç›¸ä¼¼çš„åŠ¨è¯åˆ†ç»„"""
        groups = defaultdict(list)
        
        # ç²¾ç¡®çš„åŠ¨è¯å¯¹åº”å…³ç³»
        verb_mapping = {
            'bin': 'sein', 'bist': 'sein', 'ist': 'sein', 'sind': 'sein', 'seid': 'sein',
            'war': 'sein', 'warst': 'sein', 'waren': 'sein', 'wart': 'sein',
            
            'habe': 'haben', 'hast': 'haben', 'hat': 'haben', 
            'hatte': 'haben', 'hattest': 'haben', 'hatten': 'haben', 'hattet': 'haben',
            
            'sehe': 'sehen', 'siehst': 'sehen', 'sieht': 'sehen',
            'sah': 'sehen', 'sahst': 'sehen', 'sahen': 'sehen', 'saht': 'sehen',
            
            'gehe': 'gehen', 'gehst': 'gehen', 'geht': 'gehen',
            'ging': 'gehen', 'gingst': 'gehen', 'gingen': 'gehen', 'gingt': 'gehen',
            
            'komme': 'kommen', 'kommst': 'kommen', 'kommt': 'kommen',
            'kam': 'kommen', 'kamst': 'kommen', 'kamen': 'kommen', 'kamt': 'kommen',
            
            'mache': 'machen', 'machst': 'machen', 'macht': 'machen',
            'machte': 'machen', 'machtest': 'machen', 'machten': 'machen', 'machtet': 'machen',
            
            'sage': 'sagen', 'sagst': 'sagen', 'sagt': 'sagen',
            'sagte': 'sagen', 'sagtest': 'sagen', 'sagten': 'sagen', 'sagtet': 'sagen',
            
            'bade': 'baden', 'badest': 'baden', 'badet': 'baden'
        }
        
        for verb_data in verbs:
            lemma = verb_data[0].lower()
            
            # ä½¿ç”¨ç²¾ç¡®æ˜ å°„æˆ–è‡ªèº«
            base_form = verb_mapping.get(lemma, lemma)
            
            # å¦‚æœlemmaä»¥-enç»“å°¾ï¼Œå®ƒå¯èƒ½æ˜¯ä¸å®šå¼ï¼Œç”¨ä½œbase
            if lemma.endswith('en'):
                base_form = lemma
            
            groups[base_form].append(verb_data)
        
        return {k: v for k, v in groups.items() if len(v) > 1}
    
    def group_singular_plural_nouns(self, nouns):
        """å°†å•å¤æ•°åè¯åˆ†ç»„"""
        groups = defaultdict(list)
        
        # ç²¾ç¡®çš„å•å¤æ•°å¯¹åº”å…³ç³»
        plural_mapping = {
            'zÃ¼ge': 'zug', 'zÃ¼gen': 'zug',
            'hÃ¤user': 'haus', 'hÃ¤usern': 'haus',
            'mÃ¤nner': 'mann', 'mÃ¤nnern': 'mann', 
            'kinder': 'kind', 'kindern': 'kind',
            'frauen': 'frau',
            'freunde': 'freund',
            'jahre': 'jahr', 
            'haare': 'haar',
            'geschÃ¤fte': 'geschÃ¤ft',
            'geschenke': 'geschenk',
            'probleme': 'problem',
            'spiele': 'spiel',
            'worte': 'wort', 'wÃ¶rter': 'wort',
            'fische': 'fisch',
            'schuhe': 'schuh',
            'preise': 'preis',
            'punkte': 'punkt',
            'berge': 'berg',
            'arme': 'arm',
            'sterne': 'stern',
            'witze': 'witz',
            'sprachkurse': 'sprachkurs',
            'integrationskurse': 'integrationskurs',
            'termine': 'termin',
            'pakete': 'paket',
            'anrufe': 'anruf',
            'abgase': 'abgas',
            'feiertage': 'feiertag',
            'getrÃ¤nke': 'getrÃ¤nk',
            'papiere': 'papier',
            'prospekte': 'prospekt',
            'formulare': 'formular',
            'feuerzeuge': 'feuerzeug',
            'boote': 'boot',
            'monate': 'monat',
            'versuche': 'versuch',
            'vitamine': 'vitamin',
            'lehrwerke': 'lehrwerk',
            'sonderangebote': 'sonderangebot',
            'schritte': 'schritt',
            'tische': 'tisch',
            'hause': 'haus'  # zu Hause -> Haus
        }
        
        for noun_data in nouns:
            lemma = noun_data[0].lower()
            
            # ä½¿ç”¨ç²¾ç¡®æ˜ å°„
            singular_form = plural_mapping.get(lemma, lemma)
            
            groups[singular_form].append(noun_data)
        
        return {k: v for k, v in groups.items() if len(v) > 1}
    
    def merge_duplicate_lemmas(self, verb_groups, noun_groups):
        """åˆå¹¶é‡å¤çš„è¯æ¡"""
        print(f"ğŸ”§ å¼€å§‹è‡ªåŠ¨åˆå¹¶...")
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # åˆå¹¶åŠ¨è¯ç»„
            for base_verb, variants in verb_groups.items():
                if len(variants) > 1:
                    self.merge_verb_group(cursor, base_verb, variants)
            
            # åˆå¹¶åè¯ç»„  
            for base_noun, variants in noun_groups.items():
                if len(variants) > 1:
                    self.merge_noun_group(cursor, base_noun, variants)
            
            conn.commit()
            print(f"âœ… è‡ªåŠ¨åˆå¹¶å®Œæˆ!")
            
        except Exception as e:
            print(f"âŒ åˆå¹¶å¤±è´¥: {e}")
            conn.rollback()
            raise
        finally:
            conn.close()
    
    def merge_verb_group(self, cursor, base_verb, variants):
        """åˆå¹¶ä¸€ç»„åŠ¨è¯å˜ä½“"""
        # é€‰æ‹©æœ€å¥½çš„ä¸»è¯æ¡ï¼ˆä¼˜å…ˆä¸å®šå¼å½¢å¼ï¼‰
        main_lemma = self.select_main_verb_lemma(variants)
        other_lemmas = [v for v in variants if v[2] != main_lemma[2]]
        
        if other_lemmas:
            print(f"  ğŸ“ åŠ¨è¯: {main_lemma[0]} <- {[v[0] for v in other_lemmas]}")
        
        for other_lemma in other_lemmas:
            lemma_text, pos, lemma_id, cefr, freq = other_lemma
            
            # å°†å…¶ä»–è¯æ¡è½¬ä¸ºword_forms
            self.convert_lemma_to_word_form(cursor, lemma_id, main_lemma[2], lemma_text)
            
            # è¿ç§»ç›¸å…³æ•°æ®
            self.migrate_lemma_data(cursor, lemma_id, main_lemma[2])
            
            # åˆ é™¤åŸè¯æ¡
            cursor.execute("DELETE FROM word_lemmas WHERE id = ?", (lemma_id,))
            
            self.stats['lemmas_merged'] += 1
            self.stats['forms_moved'] += 1
    
    def merge_noun_group(self, cursor, base_noun, variants):
        """åˆå¹¶ä¸€ç»„åè¯å˜ä½“"""
        main_lemma = self.select_main_noun_lemma(variants)
        other_lemmas = [v for v in variants if v[2] != main_lemma[2]]
        
        if other_lemmas:
            print(f"  ğŸ“ åè¯: {main_lemma[0]} <- {[v[0] for v in other_lemmas]}")
        
        for other_lemma in other_lemmas:
            lemma_text, pos, lemma_id, cefr, freq = other_lemma
            
            # å¦‚æœæ˜¯å¤æ•°å½¢å¼ï¼Œæ›´æ–°ä¸»è¯æ¡çš„å¤æ•°ä¿¡æ¯
            if lemma_text.lower() != main_lemma[0].lower():
                self.update_plural_info(cursor, main_lemma[2], lemma_text)
            
            # è¿ç§»ç›¸å…³æ•°æ®
            self.migrate_lemma_data(cursor, lemma_id, main_lemma[2])
            
            # åˆ é™¤åŸè¯æ¡
            cursor.execute("DELETE FROM word_lemmas WHERE id = ?", (lemma_id,))
            
            self.stats['lemmas_merged'] += 1
    
    def select_main_verb_lemma(self, variants):
        """ä¸ºåŠ¨è¯é€‰æ‹©æœ€ä½³ä¸»è¯æ¡ï¼ˆä¼˜å…ˆä¸å®šå¼ï¼‰"""
        # ä¼˜å…ˆé€‰æ‹©ä»¥-enç»“å°¾çš„ä¸å®šå¼
        infinitives = [v for v in variants if v[0].lower().endswith('en')]
        if infinitives:
            return max(infinitives, key=lambda v: (v[4] or 0, len(v[0])))  # æŒ‰é¢‘ç‡å’Œé•¿åº¦
        
        # å¦åˆ™é€‰æ‹©é¢‘ç‡æœ€é«˜æˆ–CEFRçº§åˆ«æœ€å¥½çš„
        return self.select_main_lemma(variants)
    
    def select_main_noun_lemma(self, variants):
        """ä¸ºåè¯é€‰æ‹©æœ€ä½³ä¸»è¯æ¡ï¼ˆä¼˜å…ˆå•æ•°ï¼‰"""
        # å¯å‘å¼ï¼šé€šå¸¸è¾ƒçŸ­çš„æ˜¯å•æ•°å½¢å¼
        return min(variants, key=lambda v: (len(v[0]), -(v[4] or 0)))
    
    def select_main_lemma(self, variants):
        """é€šç”¨çš„ä¸»è¯æ¡é€‰æ‹©é€»è¾‘"""
        def sort_key(variant):
            lemma, pos, lemma_id, cefr, freq = variant
            freq_score = freq if freq else 0
            cefr_score = {'A1': 4, 'A2': 3, 'B1': 2, 'B2': 1}.get(cefr, 0)
            return (freq_score, cefr_score, len(lemma))
        
        return max(variants, key=sort_key)
    
    def convert_lemma_to_word_form(self, cursor, old_lemma_id, new_lemma_id, form_text):
        """å°†è¯æ¡è½¬æ¢ä¸ºè¯å½¢"""
        cursor.execute("""
            INSERT OR IGNORE INTO word_forms (lemma_id, form, feature_key, feature_value)
            VALUES (?, ?, ?, ?)
        """, (new_lemma_id, form_text, "variant", "inflected_form"))
    
    def update_plural_info(self, cursor, main_lemma_id, plural_form):
        """æ›´æ–°ä¸»è¯æ¡çš„å¤æ•°ä¿¡æ¯"""
        cursor.execute("""
            UPDATE word_lemmas 
            SET notes = CASE 
                WHEN notes IS NULL THEN ? 
                WHEN notes NOT LIKE '%plural:%' THEN notes || ' ' || ?
                ELSE notes
            END
            WHERE id = ?
        """, (f"plural:{plural_form}", f"plural:{plural_form}", main_lemma_id))
    
    def migrate_lemma_data(self, cursor, old_lemma_id, new_lemma_id):
        """è¿ç§»è¯æ¡ç›¸å…³çš„æ‰€æœ‰æ•°æ®"""
        
        # è¿ç§»ç¿»è¯‘æ•°æ®ï¼ˆé¿å…é‡å¤ï¼‰
        cursor.execute("""
            INSERT OR IGNORE INTO translations (lemma_id, lang_code, text, source)
            SELECT ?, lang_code, text, source 
            FROM translations 
            WHERE lemma_id = ?
        """, (new_lemma_id, old_lemma_id))
        
        cursor.execute("DELETE FROM translations WHERE lemma_id = ?", (old_lemma_id,))
        
        # è¿ç§»ä¾‹å¥æ•°æ®
        cursor.execute("""
            INSERT OR IGNORE INTO examples (lemma_id, de_text, en_text, zh_text, level)
            SELECT ?, de_text, en_text, zh_text, level
            FROM examples 
            WHERE lemma_id = ?
        """, (new_lemma_id, old_lemma_id))
        
        cursor.execute("DELETE FROM examples WHERE lemma_id = ?", (old_lemma_id,))
        
        # è¿ç§»è¯å½¢æ•°æ®
        cursor.execute("""
            UPDATE word_forms 
            SET lemma_id = ? 
            WHERE lemma_id = ?
        """, (new_lemma_id, old_lemma_id))
    
    def print_final_stats(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡"""
        elapsed = datetime.now() - self.stats['start_time']
        
        print(f"\nğŸ‰ é‡å¤è¯æ¡è‡ªåŠ¨ä¿®å¤å®Œæˆ!")
        print("=" * 50)
        print(f"åˆå¹¶çš„è¯æ¡æ•°: {self.stats['lemmas_merged']}")
        print(f"è½¬æ¢çš„è¯å½¢æ•°: {self.stats['forms_moved']}")  
        print(f"æ€»ç”¨æ—¶: {elapsed}")
        
        if self.stats['lemmas_merged'] > 0:
            print(f"\nâœ… ä¿®å¤æˆåŠŸ! ç°åœ¨:")
            print("   â€¢ sehe/sehen å·²åˆå¹¶ä¸º sehen")
            print("   â€¢ Zug/ZÃ¼ge å·²åˆå¹¶ä¸º Zug (å¤æ•°ä¿¡æ¯ä¿å­˜åœ¨notesä¸­)")
            print("   â€¢ habe/haben/hat å·²åˆå¹¶ä¸º haben")
            print("   â€¢ æ‰€æœ‰å˜ä½å½¢å¼ç°åœ¨æŒ‡å‘æ­£ç¡®çš„è¯æ¡")

def main():
    fixer = AutoDuplicateFixer()
    return fixer.run_auto_fix()

if __name__ == "__main__":
    main()