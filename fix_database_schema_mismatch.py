#!/usr/bin/env python3
"""
æ•°æ®åº“æ¶æ„ä¸åŒ¹é…ä¿®å¤è„šæœ¬
å°†å¢å¼ºæ¶æ„(lemma_senses, noun_props, verb_props)çš„æ•°æ®è¿ç§»åˆ°ç®€å•æ¶æ„(translationsè¡¨)
ç¡®ä¿UIèƒ½æ­£ç¡®æ˜¾ç¤ºç¿»è¯‘æ•°æ®
"""
import sqlite3
import json
import sys
import os
from datetime import datetime

# ç›´æ¥è®¾ç½®è·¯å¾„ï¼Œä¸ä¾èµ–dotenv
sys.path.append(os.getcwd())

class DatabaseSchemaMigrator:
    """æ•°æ®åº“æ¶æ„è¿ç§»å™¨ - ä¿®å¤æ˜¾ç¤ºé—®é¢˜"""
    
    def __init__(self):
        self.db_path = 'data/app.db'
        self.stats = {
            'words_processed': 0,
            'translations_created': 0,
            'examples_migrated': 0,
            'errors': 0,
            'start_time': datetime.now()
        }
    
    def analyze_current_state(self):
        """åˆ†æå½“å‰æ•°æ®åº“çŠ¶æ€"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # æ£€æŸ¥è¡¨ç»“æ„
            print("ğŸ“Š æ•°æ®åº“è¡¨åˆ†æ:")
            
            # æ£€æŸ¥word_lemmas
            cursor.execute("SELECT COUNT(*) FROM word_lemmas")
            lemma_count = cursor.fetchone()[0]
            print(f"   word_lemmas: {lemma_count} æ¡")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ¶æ„è¡¨
            cursor.execute("""
                SELECT name FROM sqlite_master 
                WHERE type='table' AND name IN ('lemma_senses', 'noun_props', 'verb_props')
            """)
            enhanced_tables = [row[0] for row in cursor.fetchall()]
            print(f"   å¢å¼ºæ¶æ„è¡¨: {enhanced_tables}")
            
            if enhanced_tables:
                cursor.execute("SELECT COUNT(*) FROM lemma_senses")
                sense_count = cursor.fetchone()[0]
                print(f"   lemma_senses: {sense_count} æ¡")
            
            # æ£€æŸ¥translationsè¡¨
            cursor.execute("SELECT COUNT(*) FROM translations")
            translation_count = cursor.fetchone()[0]
            print(f"   translations: {translation_count} æ¡")
            
            # æ£€æŸ¥problem cases
            cursor.execute("""
                SELECT wl.lemma, ls.gloss_en, ls.gloss_zh, 
                       COUNT(t.id) as translation_count
                FROM word_lemmas wl
                LEFT JOIN lemma_senses ls ON ls.lemma_id = wl.id  
                LEFT JOIN translations t ON t.lemma_id = wl.id
                GROUP BY wl.id
                HAVING translation_count = 0 AND (ls.gloss_en IS NOT NULL OR ls.gloss_zh IS NOT NULL)
                LIMIT 10
            """)
            problem_words = cursor.fetchall()
            
            print(f"\nâŒ å‘ç°é—®é¢˜å•è¯ (æœ‰glossä½†æ— translations): {len(problem_words)}ä¸ª")
            for word in problem_words:
                print(f"   - {word[0]}: EN='{word[1]}' ZH='{word[2]}'")
            
            return {
                'lemma_count': lemma_count,
                'translation_count': translation_count,
                'enhanced_tables': enhanced_tables,
                'problem_count': len(problem_words)
            }
            
        finally:
            conn.close()
    
    def migrate_enhanced_to_simple(self):
        """å°†å¢å¼ºæ¶æ„æ•°æ®è¿ç§»åˆ°ç®€å•æ¶æ„"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            print("\nğŸ”„ å¼€å§‹è¿ç§»å¢å¼ºæ¶æ„æ•°æ®...")
            
            # æŸ¥æ‰¾æ‰€æœ‰æœ‰glossä½†æ²¡æœ‰translationsçš„è¯æ±‡
            cursor.execute("""
                SELECT wl.id, wl.lemma, ls.gloss_en, ls.gloss_zh, ls.upos
                FROM word_lemmas wl
                JOIN lemma_senses ls ON ls.lemma_id = wl.id
                LEFT JOIN translations t ON t.lemma_id = wl.id
                WHERE t.id IS NULL 
                AND (ls.gloss_en IS NOT NULL OR ls.gloss_zh IS NOT NULL)
            """)
            
            words_to_migrate = cursor.fetchall()
            print(f"   æ‰¾åˆ° {len(words_to_migrate)} ä¸ªéœ€è¦è¿ç§»çš„è¯æ±‡")
            
            for lemma_id, lemma, gloss_en, gloss_zh, upos in words_to_migrate:
                self.stats['words_processed'] += 1
                print(f"   è¿ç§»: {lemma} ({upos})")
                
                try:
                    # åˆ›å»ºè‹±æ–‡ç¿»è¯‘
                    if gloss_en and gloss_en.strip():
                        cursor.execute("""
                            INSERT INTO translations (lemma_id, lang_code, text, source)
                            VALUES (?, ?, ?, ?)
                        """, (lemma_id, "en", gloss_en.strip(), "migrated_from_enhanced"))
                        self.stats['translations_created'] += 1
                    
                    # åˆ›å»ºä¸­æ–‡ç¿»è¯‘  
                    if gloss_zh and gloss_zh.strip():
                        cursor.execute("""
                            INSERT INTO translations (lemma_id, lang_code, text, source)
                            VALUES (?, ?, ?, ?)
                        """, (lemma_id, "zh", gloss_zh.strip(), "migrated_from_enhanced"))
                        self.stats['translations_created'] += 1
                    
                    # è¿ç§»examplesè¡¨æ•°æ®
                    cursor.execute("""
                        SELECT de_text, en_text, zh_text FROM examples 
                        WHERE sense_id IN (SELECT id FROM lemma_senses WHERE lemma_id = ?)
                        AND lemma_id IS NULL
                    """, (lemma_id,))
                    
                    examples = cursor.fetchall()
                    for de_text, en_text, zh_text in examples:
                        if de_text and de_text.strip():
                            cursor.execute("""
                                UPDATE examples 
                                SET lemma_id = ?
                                WHERE de_text = ? AND lemma_id IS NULL
                            """, (lemma_id, de_text))
                            self.stats['examples_migrated'] += 1
                    
                    # æäº¤è¿™ä¸ªè¯çš„æ›´æ”¹
                    conn.commit()
                    
                except Exception as e:
                    print(f"     âŒ è¿ç§»å¤±è´¥: {e}")
                    self.stats['errors'] += 1
                    conn.rollback()
            
            print("âœ… æ•°æ®è¿ç§»å®Œæˆ")
            
        finally:
            conn.close()
    
    def add_missing_basic_translations(self):
        """ä¸ºæ²¡æœ‰ä»»ä½•ç¿»è¯‘çš„è¯æ±‡æ·»åŠ åŸºç¡€ç¿»è¯‘"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # å¸¸ç”¨å¾·è¯­å•è¯åŸºç¡€ç¿»è¯‘åº“
        basic_translations = {
            "kreuzen": {
                "pos": "verb",
                "translations_en": ["to cross", "to intersect", "to cruise"],
                "translations_zh": ["äº¤å‰", "ç©¿è¿‡", "å·¡èˆª"]
            },
            "arbeiten": {
                "pos": "verb", 
                "translations_en": ["to work"],
                "translations_zh": ["å·¥ä½œ"]
            },
            "leben": {
                "pos": "verb",
                "translations_en": ["to live"],
                "translations_zh": ["ç”Ÿæ´»", "å±…ä½"]
            },
            "kaufen": {
                "pos": "verb",
                "translations_en": ["to buy"],
                "translations_zh": ["ä¹°"]
            },
            "verkaufen": {
                "pos": "verb",
                "translations_en": ["to sell"],
                "translations_zh": ["å–"]
            },
            "schlafen": {
                "pos": "verb",
                "translations_en": ["to sleep"],
                "translations_zh": ["ç¡è§‰"]
            },
            "fahren": {
                "pos": "verb",
                "translations_en": ["to drive", "to go"],
                "translations_zh": ["å¼€è½¦", "è¡Œé©¶"]
            },
            "laufen": {
                "pos": "verb",
                "translations_en": ["to run", "to walk"],
                "translations_zh": ["è·‘", "èµ°"]
            },
            "machen": {
                "pos": "verb",
                "translations_en": ["to make", "to do"],
                "translations_zh": ["åš", "åˆ¶ä½œ"]
            },
            "sagen": {
                "pos": "verb",
                "translations_en": ["to say"],
                "translations_zh": ["è¯´"]
            },
            "sehen": {
                "pos": "verb",
                "translations_en": ["to see"],
                "translations_zh": ["çœ‹è§"]
            },
            "wissen": {
                "pos": "verb",
                "translations_en": ["to know"],
                "translations_zh": ["çŸ¥é“"]
            },
            "Freund": {
                "pos": "noun",
                "translations_en": ["friend"],
                "translations_zh": ["æœ‹å‹"]
            },
            "Buch": {
                "pos": "noun",
                "translations_en": ["book"],
                "translations_zh": ["ä¹¦"]
            },
            "Zeit": {
                "pos": "noun",
                "translations_en": ["time"],
                "translations_zh": ["æ—¶é—´"]
            },
            "Haus": {
                "pos": "noun",
                "translations_en": ["house"],
                "translations_zh": ["æˆ¿å­"]
            }
        }
        
        try:
            print("\nğŸ“š æ·»åŠ åŸºç¡€ç¿»è¯‘...")
            
            for lemma, data in basic_translations.items():
                # æ£€æŸ¥è¯æ±‡æ˜¯å¦å­˜åœ¨ä¸”ç¼ºå°‘ç¿»è¯‘
                cursor.execute("""
                    SELECT wl.id FROM word_lemmas wl
                    LEFT JOIN translations t ON t.lemma_id = wl.id
                    WHERE wl.lemma = ? AND t.id IS NULL
                """, (lemma,))
                
                result = cursor.fetchone()
                if result:
                    lemma_id = result[0]
                    print(f"   æ·»åŠ ç¿»è¯‘: {lemma}")
                    
                    # æ·»åŠ è‹±æ–‡ç¿»è¯‘
                    for en_text in data["translations_en"]:
                        cursor.execute("""
                            INSERT INTO translations (lemma_id, lang_code, text, source)
                            VALUES (?, ?, ?, ?)
                        """, (lemma_id, "en", en_text, "basic_fallback"))
                        self.stats['translations_created'] += 1
                    
                    # æ·»åŠ ä¸­æ–‡ç¿»è¯‘
                    for zh_text in data["translations_zh"]:
                        cursor.execute("""
                            INSERT INTO translations (lemma_id, lang_code, text, source)
                            VALUES (?, ?, ?, ?)
                        """, (lemma_id, "zh", zh_text, "basic_fallback"))
                        self.stats['translations_created'] += 1
                    
                    conn.commit()
            
            print("âœ… åŸºç¡€ç¿»è¯‘æ·»åŠ å®Œæˆ")
            
        finally:
            conn.close()
    
    def verify_fix(self):
        """éªŒè¯ä¿®å¤ç»“æœ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            print("\nğŸ” éªŒè¯ä¿®å¤ç»“æœ:")
            
            # æ£€æŸ¥ä¹‹å‰çš„é—®é¢˜è¯æ±‡
            test_words = ['kreuzen', 'bezahlen', 'arbeiten', 'leben']
            
            for word in test_words:
                cursor.execute("""
                    SELECT wl.lemma, 
                           COUNT(CASE WHEN t.lang_code = 'en' THEN 1 END) as en_count,
                           COUNT(CASE WHEN t.lang_code = 'zh' THEN 1 END) as zh_count,
                           GROUP_CONCAT(CASE WHEN t.lang_code = 'en' THEN t.text END) as en_translations,
                           GROUP_CONCAT(CASE WHEN t.lang_code = 'zh' THEN t.text END) as zh_translations
                    FROM word_lemmas wl
                    LEFT JOIN translations t ON t.lemma_id = wl.id
                    WHERE wl.lemma = ?
                    GROUP BY wl.id
                """, (word,))
                
                result = cursor.fetchone()
                if result:
                    lemma, en_count, zh_count, en_trans, zh_trans = result
                    status = "âœ…" if (en_count > 0 and zh_count > 0) else "âŒ"
                    print(f"   {status} {lemma}: EN({en_count}) ZH({zh_count})")
                    if en_trans:
                        print(f"      EN: {en_trans}")
                    if zh_trans:
                        print(f"      ZH: {zh_trans}")
                else:
                    print(f"   âŒ {word}: æœªæ‰¾åˆ°")
            
            # æ€»ä½“ç»Ÿè®¡
            cursor.execute("""
                SELECT 
                    COUNT(DISTINCT wl.id) as total_words,
                    COUNT(DISTINCT CASE WHEN t.id IS NOT NULL THEN wl.id END) as words_with_translations,
                    COUNT(t.id) as total_translations
                FROM word_lemmas wl
                LEFT JOIN translations t ON t.lemma_id = wl.id
            """)
            
            total_words, words_with_trans, total_trans = cursor.fetchone()
            coverage = (words_with_trans / total_words * 100) if total_words > 0 else 0
            
            print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
            print(f"   æ€»è¯æ±‡æ•°: {total_words}")
            print(f"   æœ‰ç¿»è¯‘çš„è¯æ±‡: {words_with_trans}")
            print(f"   ç¿»è¯‘è¦†ç›–ç‡: {coverage:.1f}%")
            print(f"   æ€»ç¿»è¯‘æ•°: {total_trans}")
            
        finally:
            conn.close()
    
    def print_final_stats(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡"""
        elapsed = datetime.now() - self.stats['start_time']
        
        print(f"\nğŸ‰ æ•°æ®åº“æ¶æ„ä¿®å¤å®Œæˆ!")
        print(f"=" * 50)
        print(f"å¤„ç†è¯æ±‡: {self.stats['words_processed']}")
        print(f"åˆ›å»ºç¿»è¯‘: {self.stats['translations_created']}")
        print(f"è¿ç§»ä¾‹å¥: {self.stats['examples_migrated']}")
        print(f"é”™è¯¯æ•°é‡: {self.stats['errors']}")
        print(f"æ€»ç”¨æ—¶: {elapsed}")
        print("\nğŸš€ ç°åœ¨åˆ·æ–°æµè§ˆå™¨ï¼Œæœç´¢ 'kreuzen' åº”è¯¥èƒ½çœ‹åˆ°ç¿»è¯‘äº†!")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ä¿®å¤æ•°æ®åº“æ¶æ„ä¸åŒ¹é…é—®é¢˜')
    parser.add_argument('--dry-run', action='store_true', help='è¯•è¿è¡Œæ¨¡å¼')
    parser.add_argument('--analyze-only', action='store_true', help='åªåˆ†æä¸ä¿®å¤')
    
    args = parser.parse_args()
    
    print("ğŸ”§ æ•°æ®åº“æ¶æ„ä¿®å¤å·¥å…·")
    print("=" * 50)
    print("é—®é¢˜: å¯¼å…¥è„šæœ¬ä½¿ç”¨å¢å¼ºæ¶æ„ï¼Œä½†UIæœŸæœ›ç®€å•æ¶æ„")
    print("è§£å†³: å°†gloss_en/gloss_zhè¿ç§»åˆ°translationsè¡¨")
    
    migrator = DatabaseSchemaMigrator()
    
    # 1. åˆ†æå½“å‰çŠ¶æ€
    print("\nğŸ“Š ç¬¬1æ­¥: åˆ†æå½“å‰æ•°æ®åº“çŠ¶æ€")
    state = migrator.analyze_current_state()
    
    if args.analyze_only:
        print("\nâš ï¸ ä»…åˆ†ææ¨¡å¼ - é€€å‡º")
        return
    
    if state['problem_count'] == 0:
        print("\nâœ… æœªå‘ç°æ¶æ„ä¸åŒ¹é…é—®é¢˜!")
        return
    
    if args.dry_run:
        print(f"\nâš ï¸ è¯•è¿è¡Œæ¨¡å¼ - å°†ä¼šè¿ç§» {state['problem_count']} ä¸ªè¯æ±‡")
        return
    
    # 2. æ‰§è¡Œè¿ç§»
    print("\nğŸ”„ ç¬¬2æ­¥: è¿ç§»å¢å¼ºæ¶æ„æ•°æ®")
    migrator.migrate_enhanced_to_simple()
    
    # 3. æ·»åŠ åŸºç¡€ç¿»è¯‘
    print("\nğŸ“š ç¬¬3æ­¥: æ·»åŠ å¸¸ç”¨è¯æ±‡åŸºç¡€ç¿»è¯‘")  
    migrator.add_missing_basic_translations()
    
    # 4. éªŒè¯ä¿®å¤
    print("\nğŸ” ç¬¬4æ­¥: éªŒè¯ä¿®å¤ç»“æœ")
    migrator.verify_fix()
    
    # 5. æ‰“å°ç»Ÿè®¡
    migrator.print_final_stats()

if __name__ == "__main__":
    main()