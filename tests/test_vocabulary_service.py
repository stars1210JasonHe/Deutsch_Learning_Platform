"""
VocabularyService æµ‹è¯•æ¨¡å—
æµ‹è¯•æœç´¢ã€ç¼“å­˜ã€OpenAIé›†æˆç­‰åŠŸèƒ½
"""
import pytest
import asyncio
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from app.db.base import Base
from app.models.user import User, UserRole
from app.models.word import WordLemma, Translation, Example, WordForm
from app.services.vocabulary_service import VocabularyService
from app.core.security import get_password_hash


# æµ‹è¯•æ•°æ®åº“
TEST_DATABASE_URL = "sqlite:///./test.db"
test_engine = create_engine(TEST_DATABASE_URL, connect_args={"check_same_thread": False})
TestSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=test_engine)


class TestVocabularyService:
    """VocabularyService æµ‹è¯•ç±»"""
    
    @classmethod
    def setup_class(cls):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        # åˆ›å»ºæµ‹è¯•æ•°æ®åº“è¡¨
        Base.metadata.create_all(bind=test_engine)
        cls.db = TestSessionLocal()
        cls.vocab_service = VocabularyService()
        
        # åˆ›å»ºæµ‹è¯•ç”¨æˆ·
        cls.test_user = User(
            email="test@vocabulary.com",
            password_hash=get_password_hash("test123"),
            role=UserRole.USER
        )
        cls.db.add(cls.test_user)
        cls.db.commit()
        cls.db.refresh(cls.test_user)
        
        print("âœ… æµ‹è¯•ç¯å¢ƒè®¾ç½®å®Œæˆ")

    @classmethod
    def teardown_class(cls):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        cls.db.close()
        # åˆ é™¤æµ‹è¯•æ•°æ®åº“æ–‡ä»¶
        try:
            os.remove("./test.db")
            print("âœ… æµ‹è¯•æ•°æ®åº“å·²æ¸…ç†")
        except FileNotFoundError:
            pass

    def setup_method(self):
        """æ¯ä¸ªæµ‹è¯•å‰çš„è®¾ç½®"""
        # æ¸…ç†æ‰€æœ‰è¯æ±‡æ•°æ®
        self.db.query(WordForm).delete()
        self.db.query(Example).delete()
        self.db.query(Translation).delete()
        self.db.query(WordLemma).delete()
        self.db.commit()

    async def test_search_empty_database(self):
        """æµ‹è¯•ç©ºæ•°æ®åº“æœç´¢"""
        print("\nğŸ§ª æµ‹è¯•: ç©ºæ•°æ®åº“æœç´¢")
        
        # ç¡®è®¤æ•°æ®åº“ä¸ºç©º
        count = self.db.query(WordLemma).count()
        assert count == 0, f"æ•°æ®åº“åº”è¯¥ä¸ºç©ºï¼Œä½†æ‰¾åˆ°äº† {count} ä¸ªè¯æ±‡"
        
        # æœç´¢ä¸å­˜åœ¨çš„è¯æ±‡
        result = await self.vocab_service.get_or_create_word(
            self.db, "Hallo", self.test_user
        )
        
        # éªŒè¯ç»“æœ
        assert result is not None, "æœç´¢ç»“æœä¸åº”è¯¥ä¸ºç©º"
        assert result["original"] == "Hallo", f"æœŸæœ› 'Hallo'ï¼Œå®é™…å¾—åˆ° {result['original']}"
        assert result["source"] in ["openai", "database"], f"æ— æ•ˆçš„æ¥æº: {result['source']}"
        
        print(f"   âœ… æœç´¢ç»“æœ: {result['original']} ({result['pos']})")
        print(f"   âœ… æ¥æº: {result['source']}")

    async def test_search_existing_word(self):
        """æµ‹è¯•æœç´¢å·²å­˜åœ¨çš„è¯æ±‡"""
        print("\nğŸ§ª æµ‹è¯•: æœç´¢å·²å­˜åœ¨çš„è¯æ±‡")
        
        # é¢„å…ˆæ·»åŠ ä¸€ä¸ªè¯æ±‡
        test_word = WordLemma(
            lemma="gehen",
            pos="verb",
            cefr="A1",
            notes="Test word"
        )
        self.db.add(test_word)
        self.db.commit()
        self.db.refresh(test_word)
        
        # æ·»åŠ ç¿»è¯‘
        en_trans = Translation(
            lemma_id=test_word.id,
            lang_code="en",
            text="to go",
            source="test"
        )
        zh_trans = Translation(
            lemma_id=test_word.id,
            lang_code="zh",
            text="å»",
            source="test"
        )
        self.db.add(en_trans)
        self.db.add(zh_trans)
        self.db.commit()
        
        # æœç´¢è¿™ä¸ªè¯æ±‡
        result = await self.vocab_service.get_or_create_word(
            self.db, "gehen", self.test_user
        )
        
        # éªŒè¯ç»“æœ
        assert result is not None, "æœç´¢ç»“æœä¸åº”è¯¥ä¸ºç©º"
        assert result["original"] == "gehen", f"æœŸæœ› 'gehen'ï¼Œå®é™…å¾—åˆ° {result['original']}"
        assert result["source"] == "database", f"åº”è¯¥ä»æ•°æ®åº“è·å–ï¼Œå®é™…æ¥æº: {result['source']}"
        assert result["cached"] is True, "åº”è¯¥æ ‡è®°ä¸ºç¼“å­˜"
        assert "to go" in result["translations_en"], "åº”è¯¥åŒ…å«è‹±æ–‡ç¿»è¯‘ 'to go'"
        assert "å»" in result["translations_zh"], "åº”è¯¥åŒ…å«ä¸­æ–‡ç¿»è¯‘ 'å»'"
        
        print(f"   âœ… æ‰¾åˆ°å·²å­˜åœ¨è¯æ±‡: {result['original']}")
        print(f"   âœ… è‹±æ–‡ç¿»è¯‘: {result['translations_en']}")
        print(f"   âœ… ä¸­æ–‡ç¿»è¯‘: {result['translations_zh']}")

    async def test_case_insensitive_search(self):
        """æµ‹è¯•ä¸åŒºåˆ†å¤§å°å†™çš„æœç´¢"""
        print("\nğŸ§ª æµ‹è¯•: ä¸åŒºåˆ†å¤§å°å†™æœç´¢")
        
        # æ·»åŠ å°å†™è¯æ±‡
        test_word = WordLemma(
            lemma="hallo",
            pos="interjection",
            cefr="A1",
            notes="Test greeting"
        )
        self.db.add(test_word)
        self.db.commit()
        
        # ç”¨å¤§å†™æœç´¢
        result = await self.vocab_service.get_or_create_word(
            self.db, "HALLO", self.test_user
        )
        
        # éªŒè¯æ‰¾åˆ°äº†å°å†™ç‰ˆæœ¬
        assert result is not None, "åº”è¯¥æ‰¾åˆ°è¯æ±‡"
        assert result["source"] == "database", "åº”è¯¥ä»æ•°æ®åº“æ‰¾åˆ°"
        
        print(f"   âœ… å¤§å†™æœç´¢ 'HALLO' æ‰¾åˆ°å°å†™è¯æ±‡ '{result['original']}'")

    async def test_search_with_article(self):
        """æµ‹è¯•å¸¦å† è¯çš„æœç´¢"""
        print("\nğŸ§ª æµ‹è¯•: å¸¦å† è¯çš„æœç´¢")
        
        # æ·»åŠ ä¸å¸¦å† è¯çš„åè¯
        test_word = WordLemma(
            lemma="Tisch",
            pos="noun",
            cefr="A1",
            notes="Test noun"
        )
        self.db.add(test_word)
        self.db.commit()
        self.db.refresh(test_word)
        
        # æ·»åŠ å† è¯ä¿¡æ¯
        article_form = WordForm(
            lemma_id=test_word.id,
            form="der Tisch",
            feature_key="article",
            feature_value="der"
        )
        self.db.add(article_form)
        self.db.commit()
        
        # ç”¨å¸¦å† è¯çš„å½¢å¼æœç´¢
        result = await self.vocab_service.get_or_create_word(
            self.db, "der Tisch", self.test_user
        )
        
        # éªŒè¯ç»“æœ
        assert result is not None, "åº”è¯¥æ‰¾åˆ°è¯æ±‡"
        assert result["original"] == "Tisch", f"åº”è¯¥è¿”å›lemma 'Tisch'ï¼Œå®é™…: {result['original']}"
        
        print(f"   âœ… æœç´¢ 'der Tisch' æ‰¾åˆ°è¯æ±‡ '{result['original']}'")

    async def test_word_forms_search(self):
        """æµ‹è¯•è¯å½¢å˜ä½æœç´¢"""
        print("\nğŸ§ª æµ‹è¯•: è¯å½¢å˜ä½æœç´¢")
        
        # æ·»åŠ åŠ¨è¯åŠå…¶å˜ä½
        test_verb = WordLemma(
            lemma="gehen",
            pos="verb",
            cefr="A1",
            notes="Test verb"
        )
        self.db.add(test_verb)
        self.db.commit()
        self.db.refresh(test_verb)
        
        # æ·»åŠ å˜ä½å½¢å¼
        verb_form = WordForm(
            lemma_id=test_verb.id,
            form="geht",
            feature_key="tense",
            feature_value="praesens_er_sie_es"
        )
        self.db.add(verb_form)
        self.db.commit()
        
        # ç”¨å˜ä½å½¢å¼æœç´¢
        result = await self.vocab_service.get_or_create_word(
            self.db, "geht", self.test_user
        )
        
        # éªŒè¯æ‰¾åˆ°äº†åŸå½¢
        assert result is not None, "åº”è¯¥æ‰¾åˆ°è¯æ±‡"
        assert result["original"] == "gehen", f"åº”è¯¥æ‰¾åˆ°åŸå½¢ 'gehen'ï¼Œå®é™…: {result['original']}"
        
        print(f"   âœ… æœç´¢å˜ä½ 'geht' æ‰¾åˆ°åŸå½¢ '{result['original']}'")

    async def test_search_results_format(self):
        """æµ‹è¯•æœç´¢ç»“æœæ ¼å¼"""
        print("\nğŸ§ª æµ‹è¯•: æœç´¢ç»“æœæ ¼å¼")
        
        result = await self.vocab_service.get_or_create_word(
            self.db, "test", self.test_user
        )
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        required_fields = [
            "original", "pos", "translations_en", "translations_zh", 
            "cached", "source"
        ]
        
        for field in required_fields:
            assert field in result, f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}"
        
        # éªŒè¯ç±»å‹
        assert isinstance(result["translations_en"], list), "translations_enåº”è¯¥æ˜¯åˆ—è¡¨"
        assert isinstance(result["translations_zh"], list), "translations_zhåº”è¯¥æ˜¯åˆ—è¡¨"
        assert isinstance(result["cached"], bool), "cachedåº”è¯¥æ˜¯å¸ƒå°”å€¼"
        
        print("   âœ… æœç´¢ç»“æœæ ¼å¼éªŒè¯é€šè¿‡")

    def test_search_history_logging(self):
        """æµ‹è¯•æœç´¢å†å²è®°å½•"""
        print("\nğŸ§ª æµ‹è¯•: æœç´¢å†å²è®°å½•")
        
        # è¿™ä¸ªæµ‹è¯•éœ€è¦åœ¨å¼‚æ­¥å‡½æ•°å¤–è¿è¡Œ
        async def _test():
            await self.vocab_service.get_or_create_word(
                self.db, "Geschichte", self.test_user
            )
            
            # æ£€æŸ¥æœç´¢å†å²
            from app.models.search import SearchHistory
            history_count = self.db.query(SearchHistory).filter(
                SearchHistory.user_id == self.test_user.id
            ).count()
            
            assert history_count > 0, "åº”è¯¥è®°å½•æœç´¢å†å²"
            
            print(f"   âœ… æœç´¢å†å²è®°å½•æ•°: {history_count}")
        
        # è¿è¡Œå¼‚æ­¥æµ‹è¯•
        asyncio.run(_test())

    async def test_bulk_search(self):
        """æµ‹è¯•æ‰¹é‡æœç´¢æ€§èƒ½"""
        print("\nğŸ§ª æµ‹è¯•: æ‰¹é‡æœç´¢")
        
        test_words = ["Hallo", "TschÃ¼ss", "danke", "bitte", "ja", "nein"]
        results = []
        
        for word in test_words:
            result = await self.vocab_service.get_or_create_word(
                self.db, word, self.test_user
            )
            results.append(result)
        
        # éªŒè¯æ‰€æœ‰è¯æ±‡éƒ½æœ‰ç»“æœ
        assert len(results) == len(test_words), f"æœŸæœ› {len(test_words)} ä¸ªç»“æœï¼Œå¾—åˆ° {len(results)} ä¸ª"
        
        for i, result in enumerate(results):
            assert result is not None, f"ç¬¬ {i} ä¸ªæœç´¢ç»“æœä¸ºç©º"
            assert result["original"] == test_words[i], f"æœŸæœ› {test_words[i]}ï¼Œå¾—åˆ° {result['original']}"
        
        print(f"   âœ… æ‰¹é‡æœç´¢ {len(test_words)} ä¸ªè¯æ±‡å®Œæˆ")

    async def test_search_words_function(self):
        """æµ‹è¯•search_wordså‡½æ•°"""
        print("\nğŸ§ª æµ‹è¯•: search_wordså‡½æ•°")
        
        # å…ˆæ·»åŠ ä¸€äº›æµ‹è¯•æ•°æ®
        test_words_data = [
            ("Hallo", "interjection", "hello", "ä½ å¥½"),
            ("guten", "adjective", "good", "å¥½çš„"),
            ("Tag", "noun", "day", "å¤©"),
        ]
        
        for lemma, pos, en_trans, zh_trans in test_words_data:
            word = WordLemma(lemma=lemma, pos=pos, cefr="A1", notes="Test")
            self.db.add(word)
            self.db.commit()
            self.db.refresh(word)
            
            self.db.add(Translation(lemma_id=word.id, lang_code="en", text=en_trans, source="test"))
            self.db.add(Translation(lemma_id=word.id, lang_code="zh", text=zh_trans, source="test"))
        
        self.db.commit()
        
        # æµ‹è¯•æœç´¢
        result = await self.vocab_service.search_words(
            self.db, "gu", self.test_user  # åº”è¯¥æ‰¾åˆ° "guten"
        )
        
        # éªŒè¯ç»“æœ
        assert result is not None, "æœç´¢ç»“æœä¸åº”è¯¥ä¸ºç©º"
        assert "results" in result, "ç»“æœä¸­åº”è¯¥åŒ…å« 'results' å­—æ®µ"
        assert "total" in result, "ç»“æœä¸­åº”è¯¥åŒ…å« 'total' å­—æ®µ"
        assert result["total"] >= 1, f"åº”è¯¥è‡³å°‘æ‰¾åˆ°1ä¸ªç»“æœï¼Œå®é™…: {result['total']}"
        
        print(f"   âœ… æ¨¡ç³Šæœç´¢ 'gu' æ‰¾åˆ° {result['total']} ä¸ªç»“æœ")


def run_async_test(test_func):
    """è¿è¡Œå¼‚æ­¥æµ‹è¯•å‡½æ•°"""
    return asyncio.run(test_func())


# è¿è¡Œæ‰€æœ‰æµ‹è¯•çš„ä¸»å‡½æ•°
async def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    
    print("ğŸ§ª å¼€å§‹VocabularyServiceæµ‹è¯•")
    print("=" * 60)
    
    test_instance = TestVocabularyService()
    test_instance.setup_class()
    
    try:
        test_methods = [
            test_instance.test_search_empty_database,
            test_instance.test_search_existing_word,
            test_instance.test_case_insensitive_search,
            test_instance.test_search_with_article,
            test_instance.test_word_forms_search,
            test_instance.test_search_results_format,
            test_instance.test_bulk_search,
            test_instance.test_search_words_function,
        ]
        
        passed = 0
        failed = 0
        
        for i, test_method in enumerate(test_methods):
            try:
                test_instance.setup_method()  # é‡ç½®æµ‹è¯•ç¯å¢ƒ
                await test_method()
                passed += 1
                print(f"   âœ… æµ‹è¯• {i+1} é€šè¿‡")
            except Exception as e:
                failed += 1
                print(f"   âŒ æµ‹è¯• {i+1} å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        # è¿è¡ŒåŒæ­¥æµ‹è¯•
        try:
            test_instance.setup_method()
            test_instance.test_search_history_logging()
            passed += 1
            print(f"   âœ… æœç´¢å†å²æµ‹è¯•é€šè¿‡")
        except Exception as e:
            failed += 1
            print(f"   âŒ æœç´¢å†å²æµ‹è¯•å¤±è´¥: {e}")
        
        print(f"\nğŸ“Š æµ‹è¯•æ€»ç»“:")
        print(f"   é€šè¿‡: {passed}")
        print(f"   å¤±è´¥: {failed}")
        print(f"   æ€»è®¡: {passed + failed}")
        
        if failed == 0:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        else:
            print(f"âš ï¸ æœ‰ {failed} ä¸ªæµ‹è¯•å¤±è´¥")
            
    finally:
        test_instance.teardown_class()


if __name__ == "__main__":
    asyncio.run(run_all_tests())